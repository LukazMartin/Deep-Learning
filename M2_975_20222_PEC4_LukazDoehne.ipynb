{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XT4f3248T1s9"
   },
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.975 · Deep Learning · PEC4</p>\n",
    "<p style=\"margin: 0; text-align:right;\">2022-2 · Master universitario en Ciencia de datos (Data science)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informatica, Multimedia y Telecomunicaciones</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# PEC 4: Modelos generativos\n",
    "\n",
    "En esta práctica implementaremos uno de los tipos de modelos generativos más utilizados actualmente, las redes generativas adversarias, ie. **GANs**.\n",
    "\n",
    "<u>Consideraciones generales</u>:\n",
    "\n",
    "- Esta PEC debe realizarse de manera **estrictamente individual**. Cualquier indicio de copia será penalizado con un suspenso (D) para todas las partes implicadas y la posible evaluación negativa de la asignatura de forma íntegra.\n",
    "- Es necesario que el estudiante indique **todas las fuentes** que ha utilizado para la realización de la PEC. Si no es así, se considerará que el estudiante ha cometido plagio, siendo penalizado con un suspenso (D) y la posible evaluación negativa de la asignatura de forma íntegra.\n",
    "\n",
    "<u>Formato de entrega</u>:\n",
    "\n",
    "- Algunos ejercicios pueden suponer varios minutos de ejecución, por lo que la entrega debe realizarse en **formato notebook** y en **formato html**, donde se vea el código, los resultados y comentarios de cada ejercicio. Se puede exportar el notebook a HTML desde el menú File $\\to$ Download as $\\to$ HTML.\n",
    "- Existe un tipo de celda especial para albergar texto. Este tipo de celda le será muy útil para responder a las diferentes preguntas teóricas planteadas a lo largo de la actividad. Puede cambiar el tipo de celda a este tipo, en el menú: Cell $\\to$ Cell Type $\\to$ Markdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgTLOJ8ST1s_"
   },
   "source": [
    "# 0. Introducción\n",
    "\n",
    "El objetivo de esta PEC es comprender la implementación de una solución generativa, utilizando DCGANs para la generación de imágenes, mediante el conjunto de datos de referencia en deep learning más sencillo existente: MNIST.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wO8zL9tsT1tA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wijsfEliT1tB"
   },
   "source": [
    "# 1. Obtención de los datos\n",
    "\n",
    "El código para cargar los datos es el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lVsmDOFgT1tC",
    "outputId": "5d541eab-5b78-43db-9b73-ded819bee723",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "img_channels = 1\n",
    "(x_train, _), (_, _) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, img_channels)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i36uxpPUT1tD"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<p><strong>Ejercicio [1,5 pts.]:</strong>\n",
    "Añade un comentario explicativo, a cada una de las líneas de código de abajo, indicando cuál es su funcionalidad.</div>\n",
    "\n",
    "**Respuesta**:\n",
    "\n",
    "* `latent_dim = 100`: Establece la dimensión del modelo. Con esta variable podemos indicar al modelo el tamaño que va a recibir de datos. Por ejemplo, en una capa Dense.<br><br>\n",
    "* `img_rows, img_cols = 28, 28`: Indica la cantidad de filas y columnas para cada imagen. Cada imagen es grayscale y tiene un tamaño de 28x28.<br><br>\n",
    "* `img_channels = 1`: Representa el número de canales de las imágenes que utiliza el modelo. Cómo tratamos con imágenes en escala de grises, sólo hay 1 canal.<br><br>\n",
    "* `(x_train, _), (_, _) = mnist.load_data()`: La función load_data() de MNIST carga los valores (x_train, y_train), (x_test, y_test). Dado que no se utilizan los valores y_train, x_test y y_test estos son sustituidos por un guión bajo (_). x_train contiene 60.000 imágenes de tamaño 28x28 en escala de grises para entrenar modelos.<br><br>\n",
    "* `x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, img_channels)`: Cómo indica el nombre de la función, cambiamos la forma del objeto x_train para que tenga la forma adecuada para el modelo. En este caso, convertimos de un shape de (60000,28,28) a (60000,28,28,1).<br><br>\n",
    "* `x_train = x_train.astype('float32')`: Establecemos un nuevo tipo para x_train. En este caso, convertimos el valor inicial ('uint8') a ('float32').<br><br>\n",
    "* `x_train /= 255`: Normalizamos x_train. Hasta este punto los valores oscilaban entre 0 y 255. Al dividirlo por su valor máximo, normalizamos entre 0 y 1 el conjunto de entrenamiento. Esto es una práctica típica para modelos de aprendizaje para proporcionar más estabilidad a los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dvk71SllT1tD"
   },
   "source": [
    "## 2. Implementación del Generador\n",
    "\n",
    "A continuación se muestra una propuesta de generador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iS3FaXD6T1tE"
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    dropout = 0.4\n",
    "    depth = 256 # 64+64+64+64\n",
    "    dim = 7\n",
    "\n",
    "    model = Sequential()\n",
    "    # In: 100\n",
    "    # Out: dim x dim x depth\n",
    "    model.add(Dense(dim*dim*depth, input_dim=latent_dim))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Reshape((dim, dim, depth)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    # In: dim x dim x depth\n",
    "    # Out: 2*dim x 2*dim x depth/2\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2DTranspose(int(depth/8), 5, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Out: 28 x 28 x 1 grayscale image [0.0,1.0] per pix\n",
    "    model.add(Conv2DTranspose(1, 5, padding='same'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIegNjh3T1tF"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<p><strong>Ejercicio [1,75 pts.]:</strong>\n",
    "Contesta a las preguntas siguientes:\n",
    "</div>\n",
    "\n",
    "**1. ¿Cuál es la finalidad del generador?:**<br><br>\n",
    "La finalidad del generador es crear un modelo para la generación de imágenes apartir de la entrada de dimension (latent_dim). El generador toma la entrada y utiliza diferentes capas (densas, de convolución, de normalizacion...) y finalmente genera un output de tamaño 28x28 en escala de grises.<br><br>\n",
    "**2. Investigar por qué se utiliza `Upsampling` en las dos primeras capas en lugar de la `Conv2DTranspose` propuesta en DCGAN. Dar una justificación:**<br><br>\n",
    "Se utiliza Upsampling en las 2 primeras capas porque se quiere aumentar el tamaño para conseguir una salida de 28x28x1. La primera capa Upsampling convierte la entrada 7x7xN en 14x14xN, mientras que la segunda incrementa la dimensionalidad de 14x14xM a 28x28xM. La estrategia detrás de Upsampling es la duplicación de píxeles (tamaño).<br><br>\n",
    "**3. ¿Por qué se utiliza la normalización entre capas?**<br><br>\n",
    "La normalización entre capas se utiliza para proporcionar estabilidad a los datos. Al aplicar normalización, los valores altos o bajos no tienen tanto peso sobre el resultado y el peso se distribuye de manera más igualitaria. Lo que conlleva a un mejor rendimiento del modelo y ayuda a evitar problemas de gradiente y de overfitting. <br><br>\n",
    "**4. ¿Qué funciones de activación se utilizan? ¿Cuál es la razón de la sigmoide en la última capa?**<br><br>\n",
    "Se utilizan dos tipos de funciones de activación: relu y sigmoid.<br><br>\n",
    "La función de activación relu (Rectified Linear Unit) es conocida por proporcionar buenos resultados en multiples problemas de aprendizaje automático. Esta función es no lineal y transforma los valores negativos a cero y mantiene los valores positivos.<br><br>\n",
    "La activación sigmoid también es una función no lineal y típicamente se utiliza ante la capa de salida. Se utiliza sigmoid para normalizar el resultado entre 0 y 1. En este caso, se utiliza para obtener el resultado en escala de grises con valores de píxeles que oscilan entre 0 y 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xbH8yrJT1tF"
   },
   "source": [
    "## 3. Implementación del Discriminador\n",
    "\n",
    "A continuación se muestra el discriminador propuesto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qQ6dNqCUT1tG"
   },
   "outputs": [],
   "source": [
    "# (W−F+2P)/S+1\n",
    "def discriminator_model():\n",
    "    depth = 64\n",
    "    dropout = 0.4\n",
    "    input_shape = (img_rows, img_cols, img_channels)\n",
    "\n",
    "    model = Sequential()\n",
    "    # In: 28 x 28 x 1, depth = 1\n",
    "    # Out: 14 x 14 x 1, depth=64\n",
    "    model.add(Conv2D(depth, 5, strides=2, input_shape=input_shape, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv2D(depth*2, 5, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv2D(depth*4, 5, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv2D(depth*8, 5, strides=1, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    # Out: 1-dim probability\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSwu3t77T1tG"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<p><strong>Ejercicio [1,75 pts.]:</strong>\n",
    "Contesta a las preguntas siguientes:\n",
    "</div>\n",
    "\n",
    "**1. ¿Cuál es la finalidad del discriminador?:**<br><br>\n",
    "La finalidad del discriminador es clasificar datos reales y datos generados artificialmente. En este caso, se trata de clasificar imágenes. En la capa final, podemos observar que la salida es una neurona sigmoid, por lo que el discriminador calsificará de manera binaria (real o falso).<br><br>\n",
    "\n",
    "**2. ¿Cuáles son las dimensiones de los tensores y características de las variables de entrada y salida del discriminador? :**<br><br>\n",
    "Las dimensiones de la entrada son (img_rows, img_cols, img_channels). Es decir, la entrada es una imagen de tamaño 28x28x1.<br><br> La variable dropout indica el porcentaje de neuronas a desactivar en una capa durante una época de entrenamiento. La variable depth se usa para indicar la cantidad de canales que se generan. Por ejemplo, la primera capa *Conv2D(depth, 5, strides=2, input_shape=input_shape, padding='same')* indica que cogerá la entrada 28x28x1 y aplicará una convolución de kernel tamaño 5x5 con un stride de 2 y padding de 'same', obteniendo una salida de 14x14xdepth.<br><br>\n",
    "En la capa de salida, obtenemos una neurona que indicará la probabilidad de que la imagen de entrada sea real o falsa.\n",
    "\n",
    "**3. ¿Cuál es la diferencia con una CNN habitual?**<br><br>\n",
    "La diferencia es que típicamente una CNN es utilizada para tareas de clasificación multiple o segmentación de imágenes. Por ejemplo, ¿Que tipo de animal sale en la imagen? o ¿Dónde en la imagen hay un humano?. En cambio, la arquitectura GAN está diseñada para clasificiación binaria, para distinguir entre imágenes reales y artificiales.<br><br>\n",
    "Por lo que la principal diferencia reside en la arquitectura de ambas redes y, en concreto, la salida del modelo.\n",
    "\n",
    "**4. ¿Qué funciones de activación se utilizan?**<br><br>\n",
    "Se utilizan las funciones de activación LeakyReLu y sigmoid<br><br>\n",
    "La función de activación LeakyReLu es similar a la función ReLu, sólo que en este caso se añade el parámetro alpha permitiendo un pequeño gradiente y valores negativos. La función LeakyReLu multiplica alpha por el valor siempre que sea negativo y mantiene valores positivos sin cambio. f(x) = alpha * x if x < 0<br><br>\n",
    "La función de activación sigmoig se utiliza en la capa de salida. Esta función transforma la neurona en un valor entre 0 y 1, lo que genera una probabilidad para la imagen si es real o no.\n",
    "\n",
    "**5. ¿Cuál es la finalidad del dropout que encontramos en las capas?**<br><br>\n",
    "\n",
    "Dropout es una técnica utilizada para evitar el overfitting. La finalidad es que se desactivan un porcentaje de neuronas en una capa durante la fase de entrenamiento, y así, se evita depender demasiado de ciertas neuronas. Un dropout de 0.4 indica que el 40% de las neuronas de la capa son desactivadas aleatoriamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEvaMaXeT1tG"
   },
   "source": [
    "# 4. Modelo GAN\n",
    "\n",
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<p><strong>Ejercicio [1 pts.]:</strong>\n",
    "Contesta a las siguientes preguntas:\n",
    "</div>\n",
    "\n",
    "\n",
    "**1. A qué llamamos modelo GAN y por qué recibe ese nombre?:**<br><br>\n",
    "\n",
    "El modelo GAN (Generative Adversarial Network) consiste en dos componentes: el generador (e.g. generator_model()) y el discriminador (e.g. discriminator_model()).<br><br>\n",
    "La idea es entrenar un modelo que genere imagenes artificiales que no se puedan distinguir de reales y un segundo modelo cómo juez que clasifica imagenes según si son reales o falsas. Así, ambos modelos enfretados mejoran su rendimiento.<br><br>\n",
    "De ahí también proviene el nombre ya que ambos modelos son \"adversarios\". Mientras el generador aprende a generar datos plausibles, el discriminador aprende a distinguir datos falsos compitiendo entre ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5Ose4JDT1tG"
   },
   "source": [
    "## 4.1 Modelo Discriminador\n",
    "\n",
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<p><strong>Ejercicio [1 pts.]:</strong>\n",
    "Contesta a las siguientes preguntas:\n",
    "</div>\n",
    "\n",
    "\n",
    "**1. ¿Qué función de pérdida utiliza el discriminador? ¿Por qué? :**<br><br>\n",
    "\n",
    "Utiliza la función de pérdida \"binary_crossentropy\" (entropía cruzada binaria). Esta función es la que comúnmente se utiliza para problemas de clasificación binaria, donde se evalúa si el modelo a clasificado correctamente o incorrectamente. Por tanto, al tratarse de un problema binario y no de multi-clase o multi-label, se ha de usar binary_crossentropy.<br><br>\n",
    "**2. Busca en la bibliografía la razón por la que se propone utilizar `RMSProp` como optimizador en vez de otros.**<br><br>\n",
    "RMSProp (Root Mean Square Propagation) es comparado con otros optimizadores cómo Adam. Algunas ventajas de usar RMSProp para GAN es que tiene una rápida velocidad de convergencia, lo que accelera el proceso de entrenamiento y, en comparación con Adam, es más rápido para adaptarse al buscar el mínimo de la función.<br><br>\n",
    "Esto lo hace mediante un promedio exponencialmente decreciente (RMSProp), en lugar de la suma de sus gradientes(Adam).\n",
    "\n",
    "**3. ¿Cuál es la razón de utilizar decay?**<br><br>\n",
    "El parámetro \"decay\" hace referencia a la manera que RMSProp busca el mínimo de la función. Se trata del promedio exponencialmente decreciente (decaimiento) de la tasa de aprendizaje. La finalidad es controlar la tasa de aprendizaje a medidad que se acerca a la convergencia. A diferencia de otros optimizadores, este parámetro ayuda a hacer ajustes más finos (pequeños cambios) cuando el mínimo de la función esta cerca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "A9TqUWvlT1tH"
   },
   "outputs": [],
   "source": [
    "discriminator = discriminator_model()\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=RMSprop(learning_rate=0.0002, decay=6e-8),\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QVv4ughAT1tH"
   },
   "outputs": [],
   "source": [
    "generator = generator_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8UtcyY2T1tH"
   },
   "source": [
    "## 4.2 Modelo adversario\n",
    "\n",
    "El modelo adversario es únicamente el generador-discriminador apilados juntos. Los parámetros de entrenamiento son los mismos que en el modelo Discriminador, salvo por una tasa de aprendizaje reducida y la correspondiente disminución del peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "I5nelTE7T1tH"
   },
   "outputs": [],
   "source": [
    "def adversarial_model():\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=RMSprop(learning_rate=0.0001, decay=3e-8),\n",
    "                  metrics=['accuracy'])\n",
    "    discriminator.trainable = True\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KA1GHFKjT1tI",
    "outputId": "5d8460bf-8a41-4b51-9d16-7cadd37b773f"
   },
   "outputs": [],
   "source": [
    "adversarial = adversarial_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oW-P-ZulT1tI"
   },
   "source": [
    "## 4.3 Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Lhvt9kpzT1tI"
   },
   "outputs": [],
   "source": [
    "def plot_images(saveToFile=False, fake=True, samples=16, noise=None, epoch=0):\n",
    "    filename = 'mnist.png'\n",
    "    if fake:\n",
    "        if noise is None:\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[samples, latent_dim])\n",
    "        else:\n",
    "            filename = \"mnist_%d.png\" % epoch\n",
    "        images = generator.predict(noise)\n",
    "    else:\n",
    "        i = np.random.randint(0, x_train.shape[0], samples)\n",
    "        images = x_train[i, :, :, :]\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(images.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        image = images[i, :, :, :]\n",
    "        image = np.reshape(image, [img_rows, img_cols])\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    if saveToFile:\n",
    "        plt.savefig(filename)\n",
    "        plt.close('all')\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ihqWvljT1tI"
   },
   "source": [
    "Primero determinamos si el modelo de discriminador es correcto entrenándolo solo con imágenes reales y falsas. Después, los modelos Discriminador y Adversario entrenan uno tras otro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "L0QskfYZT1tI"
   },
   "outputs": [],
   "source": [
    "def train(train_epochs=2000, batch_size=256, save_interval=0):\n",
    "        noise_input = None\n",
    "        if save_interval>0:\n",
    "            noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_dim])\n",
    "        for epoch in range(train_epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # select a random half of images\n",
    "            images_train = x_train[np.random.randint(0, x_train.shape[0], size=batch_size), :, :, :]\n",
    "\n",
    "            # sample noise and generate a batch of new images\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_dim])\n",
    "            images_fake = generator.predict(noise)\n",
    "\n",
    "            # train the discriminator (real classified as ones and generated as zeros)\n",
    "            x = np.concatenate((images_train, images_fake))\n",
    "            y = np.ones([2*batch_size, 1])\n",
    "            y[batch_size:, :] = 0\n",
    "            d_loss = discriminator.train_on_batch(x, y)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # train the generator (wants discriminator to mistake images as real)\n",
    "            y = np.ones([batch_size, 1])\n",
    "            a_loss = adversarial.train_on_batch(noise, y)\n",
    "\n",
    "            log_msg = \"%d: [D loss: %f, acc: %f]\" % (epoch, d_loss[0], d_loss[1])\n",
    "            log_msg = \"%s  [A loss: %f, acc: %f]\" % (log_msg, a_loss[0], a_loss[1])\n",
    "            print(log_msg)\n",
    "            if save_interval>0:\n",
    "                if (epoch+1)%save_interval==0:\n",
    "                    plot_images(saveToFile=True, samples=noise_input.shape[0],\n",
    "                                noise=noise_input, epoch=(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t90u_LvjT1tJ"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<p><strong>Ejercicio [2 pts.]:</strong>\n",
    "Contesta a las siguientes preguntas:\n",
    "</div>\n",
    "\n",
    "\n",
    "**1. ¿Cuál es la finalidad de `noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_dim])`? ¿Por qué estas dimensiones?**<br><br>\n",
    "La finalidad es generar píxeles aleatorios del tamaño de las imágenes. Se genera un tensor de ruido aleatorio de tamaño batch_size (cantidad de muestras) y latent_dim (tamaño muestra). A partir de este ruido, el generador creará imágenes artificiales y dado que el ruido se ha generado aleatoriamente, las imágenes creadas serán únicas y tendrán diversidad.\n",
    "\n",
    "**2. ¿Cuál es la finalidad de `images_fake = generator.predict(noise)`?**<br><br>\n",
    "La finalidad es generar imágenes falsas utilizando el ruido creado en la línea anterior. El generador toma de entrada el vector de ruido y genera las imágenes artificiales intentando asimilarlas a imágenes reales del conjunto de entrenamiento. Dado que noise es un batch, images_fake será un lote de imágenes que posteriormente el discriminador deberá clasificar.\n",
    "\n",
    "**3. ¿Cuál es la finalidad del código que sigue?**<br><br>\n",
    "```python\n",
    "x = np.concatenate((images_train, images_fake))\n",
    "y = np.ones([2*batch_size, 1])\n",
    "y[batch_size:, :] = 0\n",
    "```\n",
    "La finalidad de np.concatenate() es combinar las imágenes reales y las generadas artificialmente por el generador. La idea es crear un nuevo conjunto de datos de test para pasarlo al discriminador.<br><br>\n",
    "La finalidad de np.ones() y y[batch_size:,:] = 0 es crear las etiquetas correspondientes al conjunto de test que se acaba de crar. np.ones() asigna el valor 1 a todas las etiquetas y la linea posterior asigna el valor 0 a las etiquetas relacionadas con imágenes generadas. Así, las imágenes reales tienen el valor 1 y las artificiales el valor 0.\n",
    "\n",
    "**4. ¿Qué realiza el comando `d_loss = discriminator.train_on_batch(x, y)`? ¿Qué devuelve?**<br><br>\n",
    "Este comando realiza el entrenamiento del discriminador. Es decir, utiliza el conjunto de datos que acabamos de generar que contiene imágenes reales y falsas y entrena sobre estas. <br><br>\n",
    "Cómo hemos especificado anteriormente se trata de un lote de datos por lo que la función será train_on_batch(). Una vez realizado el entrenamiento (ajustar los pesos y bias), está función devuelve el valor de la función de pérdida por lo que se llama d_loss (discriminator loss).\n",
    "\n",
    "**5. ¿Qué realiza el comando `a_loss = adversarial.train_on_batch(noise, y)`? ¿Qué devuelve?**<br><br>\n",
    "Este comando realiza el entrenamiento en lote del generador y discriminador. Cuando se llama esta función de lote, el modelo GAN se entrena utilizando el ruido de entrada con las etiquetas en una sola llamada. Es decir, el generador genera imágenes falsas apartir del ruido y el discriminador evalúa estas imágenes.<br><br>\n",
    "La función devuelve la perdida para el modelo GAN. En este caso, la función de pérdida vendrá determinada por ambos modelos (generador y discriminador) por lo que ambos buscarán mejorar su rendimiento. Por ello, la variable se llama a_loss (adversarial loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "b1eIHf5cT1tJ"
   },
   "outputs": [],
   "source": [
    "class ElapsedTimer(object):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "    def elapsed(self,sec):\n",
    "        if sec < 60:\n",
    "            return str(sec) + \" sec\"\n",
    "        elif sec < (60 * 60):\n",
    "            return str(sec / 60) + \" min\"\n",
    "        else:\n",
    "            return str(sec / (60 * 60)) + \" hr\"\n",
    "    def elapsed_time(self):\n",
    "        print(\"Elapsed: %s \" % self.elapsed(time.time() - self.start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rlLg8P4NT1tJ",
    "outputId": "6e9b98df-c436-4fd2-c261-e623ca2d0714"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 9s 4ms/step\n",
      "0: [D loss: 0.690863, acc: 0.558594]  [A loss: 1.228864, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "1: [D loss: 0.578506, acc: 0.500000]  [A loss: 1.366371, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "2: [D loss: 0.327868, acc: 0.996094]  [A loss: 2.265519, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "3: [D loss: 0.108103, acc: 0.994141]  [A loss: 0.000038, acc: 1.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "4: [D loss: 3.249932, acc: 0.500000]  [A loss: 0.661764, acc: 0.617188]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "5: [D loss: 0.132220, acc: 0.998047]  [A loss: 0.609459, acc: 0.726562]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "6: [D loss: 0.123631, acc: 1.000000]  [A loss: 0.536261, acc: 0.777344]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "7: [D loss: 0.125378, acc: 0.998047]  [A loss: 0.441666, acc: 0.882812]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8: [D loss: 0.124987, acc: 0.996094]  [A loss: 0.368415, acc: 0.914062]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "9: [D loss: 0.117687, acc: 0.996094]  [A loss: 0.335585, acc: 0.914062]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "10: [D loss: 0.110629, acc: 0.994141]  [A loss: 0.303884, acc: 0.933594]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "11: [D loss: 0.101198, acc: 0.998047]  [A loss: 0.300987, acc: 0.937500]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "12: [D loss: 0.094329, acc: 1.000000]  [A loss: 0.138171, acc: 0.984375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "13: [D loss: 0.085009, acc: 0.996094]  [A loss: 0.125384, acc: 0.984375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "14: [D loss: 0.074474, acc: 0.996094]  [A loss: 0.109476, acc: 0.988281]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "15: [D loss: 0.069354, acc: 0.994141]  [A loss: 0.088863, acc: 0.992188]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "16: [D loss: 0.057153, acc: 0.998047]  [A loss: 0.087145, acc: 0.992188]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "17: [D loss: 0.052957, acc: 0.996094]  [A loss: 0.048230, acc: 1.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "18: [D loss: 0.044782, acc: 1.000000]  [A loss: 0.084995, acc: 0.996094]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "19: [D loss: 0.038497, acc: 1.000000]  [A loss: 0.035602, acc: 1.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "20: [D loss: 0.034862, acc: 1.000000]  [A loss: 0.030225, acc: 1.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "21: [D loss: 0.029680, acc: 0.998047]  [A loss: 0.081304, acc: 0.996094]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "22: [D loss: 0.024379, acc: 1.000000]  [A loss: 0.103517, acc: 0.992188]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "23: [D loss: 0.020822, acc: 0.998047]  [A loss: 0.127783, acc: 0.968750]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "24: [D loss: 0.015820, acc: 1.000000]  [A loss: 0.136038, acc: 0.976562]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "25: [D loss: 0.013327, acc: 1.000000]  [A loss: 0.034829, acc: 0.996094]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "26: [D loss: 0.013064, acc: 1.000000]  [A loss: 0.084648, acc: 0.996094]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "27: [D loss: 0.009989, acc: 1.000000]  [A loss: 0.073476, acc: 0.984375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "28: [D loss: 0.008337, acc: 1.000000]  [A loss: 0.091017, acc: 0.988281]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "29: [D loss: 0.007510, acc: 1.000000]  [A loss: 0.035117, acc: 1.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "30: [D loss: 0.008203, acc: 1.000000]  [A loss: 0.075415, acc: 0.988281]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "31: [D loss: 0.007093, acc: 1.000000]  [A loss: 0.031214, acc: 0.996094]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "32: [D loss: 0.006546, acc: 1.000000]  [A loss: 0.127176, acc: 0.964844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "33: [D loss: 0.009232, acc: 0.998047]  [A loss: 0.003082, acc: 1.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "34: [D loss: 0.008796, acc: 1.000000]  [A loss: 1.413488, acc: 0.363281]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "35: [D loss: 0.010159, acc: 0.996094]  [A loss: 0.000004, acc: 1.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "36: [D loss: 0.054214, acc: 1.000000]  [A loss: 13.197759, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "37: [D loss: 0.645975, acc: 0.781250]  [A loss: 0.000000, acc: 1.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "38: [D loss: 1.738618, acc: 0.500000]  [A loss: 0.332788, acc: 0.867188]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "39: [D loss: 0.004869, acc: 1.000000]  [A loss: 0.148146, acc: 0.964844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "40: [D loss: 0.005544, acc: 1.000000]  [A loss: 0.171637, acc: 0.949219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "41: [D loss: 0.007354, acc: 1.000000]  [A loss: 0.173396, acc: 0.949219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "42: [D loss: 0.009372, acc: 1.000000]  [A loss: 0.205872, acc: 0.941406]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "43: [D loss: 0.013504, acc: 1.000000]  [A loss: 0.305583, acc: 0.886719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "44: [D loss: 0.017685, acc: 1.000000]  [A loss: 0.559314, acc: 0.695312]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "45: [D loss: 0.020992, acc: 1.000000]  [A loss: 1.054625, acc: 0.429688]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "46: [D loss: 0.022360, acc: 0.998047]  [A loss: 1.406685, acc: 0.304688]\n",
      "8/8 [==============================] - 0s 6ms/step\n",
      "47: [D loss: 0.027102, acc: 1.000000]  [A loss: 2.455020, acc: 0.074219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "48: [D loss: 0.025030, acc: 0.998047]  [A loss: 2.603094, acc: 0.042969]\n",
      "8/8 [==============================] - 0s 6ms/step\n",
      "49: [D loss: 0.037909, acc: 0.998047]  [A loss: 2.012786, acc: 0.093750]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "50: [D loss: 0.048381, acc: 0.998047]  [A loss: 5.840499, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "51: [D loss: 0.073387, acc: 0.970703]  [A loss: 0.073402, acc: 1.000000]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "52: [D loss: 0.610941, acc: 0.669922]  [A loss: 25.562607, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "53: [D loss: 4.645315, acc: 0.500000]  [A loss: 2.307390, acc: 0.023438]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "54: [D loss: 0.056382, acc: 0.998047]  [A loss: 2.868552, acc: 0.003906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "55: [D loss: 0.051632, acc: 1.000000]  [A loss: 3.174135, acc: 0.007812]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "56: [D loss: 0.056061, acc: 0.996094]  [A loss: 3.379439, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "57: [D loss: 0.092163, acc: 0.984375]  [A loss: 3.210238, acc: 0.007812]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "58: [D loss: 0.072521, acc: 0.990234]  [A loss: 3.067400, acc: 0.027344]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "59: [D loss: 0.088416, acc: 0.986328]  [A loss: 2.826926, acc: 0.042969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "60: [D loss: 0.097876, acc: 0.978516]  [A loss: 2.604374, acc: 0.074219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "61: [D loss: 0.114013, acc: 0.976562]  [A loss: 2.304423, acc: 0.101562]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "62: [D loss: 0.174706, acc: 0.937500]  [A loss: 2.023250, acc: 0.136719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "63: [D loss: 0.142142, acc: 0.958984]  [A loss: 2.595081, acc: 0.085938]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "64: [D loss: 0.144089, acc: 0.962891]  [A loss: 1.472996, acc: 0.296875]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "65: [D loss: 0.210453, acc: 0.910156]  [A loss: 5.261177, acc: 0.003906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "66: [D loss: 0.610887, acc: 0.765625]  [A loss: 0.019855, acc: 1.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "67: [D loss: 1.478180, acc: 0.513672]  [A loss: 2.949279, acc: 0.011719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "68: [D loss: 0.215173, acc: 0.941406]  [A loss: 1.079692, acc: 0.402344]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "69: [D loss: 0.263109, acc: 0.890625]  [A loss: 3.711464, acc: 0.003906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "70: [D loss: 0.414737, acc: 0.843750]  [A loss: 0.362143, acc: 0.863281]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "71: [D loss: 0.722031, acc: 0.607422]  [A loss: 4.703045, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "72: [D loss: 0.553540, acc: 0.753906]  [A loss: 0.604079, acc: 0.703125]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "73: [D loss: 0.549875, acc: 0.675781]  [A loss: 3.226651, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "74: [D loss: 0.336915, acc: 0.876953]  [A loss: 1.021971, acc: 0.386719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "75: [D loss: 0.369332, acc: 0.792969]  [A loss: 3.285308, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "76: [D loss: 0.389658, acc: 0.857422]  [A loss: 0.880697, acc: 0.449219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "77: [D loss: 0.447725, acc: 0.724609]  [A loss: 3.477403, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "78: [D loss: 0.407011, acc: 0.841797]  [A loss: 0.836777, acc: 0.460938]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "79: [D loss: 0.450532, acc: 0.732422]  [A loss: 3.286177, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "80: [D loss: 0.335051, acc: 0.880859]  [A loss: 1.147796, acc: 0.238281]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "81: [D loss: 0.339792, acc: 0.843750]  [A loss: 3.169354, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "82: [D loss: 0.330510, acc: 0.857422]  [A loss: 0.978761, acc: 0.339844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "83: [D loss: 0.376581, acc: 0.777344]  [A loss: 3.238201, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "84: [D loss: 0.350079, acc: 0.861328]  [A loss: 1.010327, acc: 0.289062]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "85: [D loss: 0.377841, acc: 0.800781]  [A loss: 3.282175, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "86: [D loss: 0.310235, acc: 0.863281]  [A loss: 1.082939, acc: 0.250000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "87: [D loss: 0.396447, acc: 0.783203]  [A loss: 3.162795, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "88: [D loss: 0.378396, acc: 0.859375]  [A loss: 0.853266, acc: 0.394531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "89: [D loss: 0.414319, acc: 0.753906]  [A loss: 3.017105, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "90: [D loss: 0.376274, acc: 0.861328]  [A loss: 0.862412, acc: 0.359375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "91: [D loss: 0.379867, acc: 0.783203]  [A loss: 2.775321, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "92: [D loss: 0.280080, acc: 0.917969]  [A loss: 1.249064, acc: 0.097656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "93: [D loss: 0.304801, acc: 0.910156]  [A loss: 2.567454, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "94: [D loss: 0.257291, acc: 0.925781]  [A loss: 1.261920, acc: 0.167969]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "95: [D loss: 0.307612, acc: 0.878906]  [A loss: 2.829165, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "96: [D loss: 0.286221, acc: 0.912109]  [A loss: 1.047826, acc: 0.222656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "97: [D loss: 0.343980, acc: 0.832031]  [A loss: 3.324636, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "98: [D loss: 0.387030, acc: 0.835938]  [A loss: 0.537628, acc: 0.750000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "99: [D loss: 0.530996, acc: 0.632812]  [A loss: 2.644790, acc: 0.000000]\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "100: [D loss: 0.314750, acc: 0.906250]  [A loss: 0.845651, acc: 0.375000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "101: [D loss: 0.371634, acc: 0.796875]  [A loss: 2.769830, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "102: [D loss: 0.301786, acc: 0.900391]  [A loss: 1.015846, acc: 0.269531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "103: [D loss: 0.340782, acc: 0.824219]  [A loss: 2.878808, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "104: [D loss: 0.304119, acc: 0.871094]  [A loss: 0.887928, acc: 0.367188]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "105: [D loss: 0.382635, acc: 0.777344]  [A loss: 3.163318, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "106: [D loss: 0.435053, acc: 0.814453]  [A loss: 0.560801, acc: 0.699219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "107: [D loss: 0.540004, acc: 0.603516]  [A loss: 2.469814, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "108: [D loss: 0.297992, acc: 0.914062]  [A loss: 1.129387, acc: 0.191406]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "109: [D loss: 0.345377, acc: 0.867188]  [A loss: 2.727931, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "110: [D loss: 0.314583, acc: 0.890625]  [A loss: 0.870489, acc: 0.378906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "111: [D loss: 0.423180, acc: 0.742188]  [A loss: 3.396269, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "112: [D loss: 0.460043, acc: 0.781250]  [A loss: 0.559610, acc: 0.730469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "113: [D loss: 0.568364, acc: 0.570312]  [A loss: 2.433826, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "114: [D loss: 0.262590, acc: 0.935547]  [A loss: 1.466152, acc: 0.039062]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "115: [D loss: 0.268447, acc: 0.945312]  [A loss: 2.215679, acc: 0.003906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "116: [D loss: 0.287593, acc: 0.917969]  [A loss: 1.155764, acc: 0.128906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "117: [D loss: 0.344312, acc: 0.851562]  [A loss: 3.711647, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "118: [D loss: 0.547447, acc: 0.761719]  [A loss: 0.376783, acc: 0.917969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "119: [D loss: 0.800130, acc: 0.509766]  [A loss: 2.301302, acc: 0.003906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "120: [D loss: 0.345099, acc: 0.875000]  [A loss: 1.109868, acc: 0.156250]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "121: [D loss: 0.365438, acc: 0.855469]  [A loss: 2.640009, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "122: [D loss: 0.395971, acc: 0.830078]  [A loss: 0.849740, acc: 0.406250]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "123: [D loss: 0.452796, acc: 0.742188]  [A loss: 2.960605, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "124: [D loss: 0.461613, acc: 0.802734]  [A loss: 0.798624, acc: 0.429688]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "125: [D loss: 0.476879, acc: 0.695312]  [A loss: 2.467702, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "126: [D loss: 0.376937, acc: 0.845703]  [A loss: 1.055083, acc: 0.175781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "127: [D loss: 0.380867, acc: 0.818359]  [A loss: 2.271269, acc: 0.003906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "128: [D loss: 0.378715, acc: 0.878906]  [A loss: 0.978032, acc: 0.253906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "129: [D loss: 0.456309, acc: 0.730469]  [A loss: 2.553402, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "130: [D loss: 0.445081, acc: 0.816406]  [A loss: 0.715838, acc: 0.519531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "131: [D loss: 0.593776, acc: 0.617188]  [A loss: 2.578686, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "132: [D loss: 0.524937, acc: 0.738281]  [A loss: 0.763787, acc: 0.492188]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "133: [D loss: 0.523241, acc: 0.660156]  [A loss: 1.952136, acc: 0.007812]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "134: [D loss: 0.424837, acc: 0.847656]  [A loss: 1.016087, acc: 0.250000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "135: [D loss: 0.472203, acc: 0.763672]  [A loss: 1.943252, acc: 0.007812]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "136: [D loss: 0.435331, acc: 0.839844]  [A loss: 0.980166, acc: 0.265625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "137: [D loss: 0.482756, acc: 0.736328]  [A loss: 2.149864, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "138: [D loss: 0.527331, acc: 0.728516]  [A loss: 0.588029, acc: 0.667969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "139: [D loss: 0.656955, acc: 0.572266]  [A loss: 2.010591, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "140: [D loss: 0.554011, acc: 0.710938]  [A loss: 0.672465, acc: 0.609375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "141: [D loss: 0.594339, acc: 0.609375]  [A loss: 1.756261, acc: 0.007812]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "142: [D loss: 0.519344, acc: 0.765625]  [A loss: 0.885913, acc: 0.289062]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "143: [D loss: 0.513824, acc: 0.714844]  [A loss: 1.710471, acc: 0.011719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "144: [D loss: 0.496418, acc: 0.798828]  [A loss: 0.812843, acc: 0.425781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "145: [D loss: 0.577075, acc: 0.636719]  [A loss: 2.262361, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "146: [D loss: 0.653252, acc: 0.654297]  [A loss: 0.483976, acc: 0.832031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "147: [D loss: 0.697029, acc: 0.546875]  [A loss: 1.594309, acc: 0.003906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "148: [D loss: 0.531062, acc: 0.746094]  [A loss: 0.872203, acc: 0.320312]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "149: [D loss: 0.542985, acc: 0.707031]  [A loss: 1.780508, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "150: [D loss: 0.560230, acc: 0.751953]  [A loss: 0.767228, acc: 0.457031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "151: [D loss: 0.603403, acc: 0.615234]  [A loss: 1.797697, acc: 0.003906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "152: [D loss: 0.585268, acc: 0.695312]  [A loss: 0.652235, acc: 0.640625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "153: [D loss: 0.636055, acc: 0.582031]  [A loss: 1.764338, acc: 0.003906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "154: [D loss: 0.583853, acc: 0.681641]  [A loss: 0.718714, acc: 0.546875]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "155: [D loss: 0.581344, acc: 0.644531]  [A loss: 1.517522, acc: 0.011719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "156: [D loss: 0.568799, acc: 0.722656]  [A loss: 0.742485, acc: 0.464844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "157: [D loss: 0.569854, acc: 0.646484]  [A loss: 1.599835, acc: 0.011719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "158: [D loss: 0.570098, acc: 0.726562]  [A loss: 0.714557, acc: 0.488281]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "159: [D loss: 0.555727, acc: 0.654297]  [A loss: 1.568793, acc: 0.007812]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "160: [D loss: 0.559572, acc: 0.693359]  [A loss: 0.701140, acc: 0.546875]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "161: [D loss: 0.550471, acc: 0.652344]  [A loss: 1.688424, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "162: [D loss: 0.555551, acc: 0.736328]  [A loss: 0.691453, acc: 0.523438]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "163: [D loss: 0.561116, acc: 0.630859]  [A loss: 1.667090, acc: 0.007812]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "164: [D loss: 0.535714, acc: 0.722656]  [A loss: 0.674533, acc: 0.574219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "165: [D loss: 0.566276, acc: 0.632812]  [A loss: 1.727544, acc: 0.003906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "166: [D loss: 0.568223, acc: 0.669922]  [A loss: 0.639532, acc: 0.636719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "167: [D loss: 0.563493, acc: 0.638672]  [A loss: 1.547910, acc: 0.011719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "168: [D loss: 0.512700, acc: 0.738281]  [A loss: 0.805129, acc: 0.375000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "169: [D loss: 0.479521, acc: 0.765625]  [A loss: 1.547384, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "170: [D loss: 0.480223, acc: 0.798828]  [A loss: 0.784095, acc: 0.410156]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "171: [D loss: 0.508232, acc: 0.724609]  [A loss: 1.807490, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "172: [D loss: 0.534270, acc: 0.689453]  [A loss: 0.555578, acc: 0.765625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "173: [D loss: 0.616014, acc: 0.582031]  [A loss: 1.830100, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "174: [D loss: 0.564685, acc: 0.648438]  [A loss: 0.657476, acc: 0.601562]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "175: [D loss: 0.526544, acc: 0.654297]  [A loss: 1.488000, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "176: [D loss: 0.461388, acc: 0.830078]  [A loss: 0.878820, acc: 0.273438]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "177: [D loss: 0.470588, acc: 0.779297]  [A loss: 1.483303, acc: 0.011719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "178: [D loss: 0.475639, acc: 0.824219]  [A loss: 0.791805, acc: 0.437500]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "179: [D loss: 0.477453, acc: 0.742188]  [A loss: 1.872408, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "180: [D loss: 0.549952, acc: 0.667969]  [A loss: 0.503165, acc: 0.816406]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "181: [D loss: 0.646378, acc: 0.580078]  [A loss: 1.821124, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "182: [D loss: 0.585133, acc: 0.619141]  [A loss: 0.710003, acc: 0.554688]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "183: [D loss: 0.529152, acc: 0.662109]  [A loss: 1.510342, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "184: [D loss: 0.492440, acc: 0.794922]  [A loss: 0.882140, acc: 0.316406]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "185: [D loss: 0.473294, acc: 0.796875]  [A loss: 1.524220, acc: 0.003906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "186: [D loss: 0.477754, acc: 0.814453]  [A loss: 0.780574, acc: 0.445312]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "187: [D loss: 0.482637, acc: 0.748047]  [A loss: 1.624370, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "188: [D loss: 0.531032, acc: 0.730469]  [A loss: 0.628003, acc: 0.636719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "189: [D loss: 0.572297, acc: 0.613281]  [A loss: 2.062705, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "190: [D loss: 0.596837, acc: 0.640625]  [A loss: 0.537857, acc: 0.738281]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "191: [D loss: 0.623578, acc: 0.585938]  [A loss: 1.658648, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "192: [D loss: 0.542527, acc: 0.685547]  [A loss: 0.767333, acc: 0.425781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "193: [D loss: 0.542399, acc: 0.681641]  [A loss: 1.491657, acc: 0.003906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "194: [D loss: 0.488600, acc: 0.800781]  [A loss: 0.807604, acc: 0.394531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "195: [D loss: 0.485172, acc: 0.761719]  [A loss: 1.552677, acc: 0.003906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "196: [D loss: 0.513365, acc: 0.732422]  [A loss: 0.667842, acc: 0.593750]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "197: [D loss: 0.558854, acc: 0.642578]  [A loss: 1.832042, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "198: [D loss: 0.583365, acc: 0.634766]  [A loss: 0.615174, acc: 0.671875]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "199: [D loss: 0.612780, acc: 0.625000]  [A loss: 1.789571, acc: 0.000000]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "200: [D loss: 0.529589, acc: 0.705078]  [A loss: 0.665970, acc: 0.605469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "201: [D loss: 0.587568, acc: 0.630859]  [A loss: 1.740562, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "202: [D loss: 0.580367, acc: 0.656250]  [A loss: 0.718461, acc: 0.515625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "203: [D loss: 0.551401, acc: 0.656250]  [A loss: 1.444972, acc: 0.015625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "204: [D loss: 0.532229, acc: 0.728516]  [A loss: 0.870302, acc: 0.289062]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "205: [D loss: 0.512717, acc: 0.742188]  [A loss: 1.475540, acc: 0.011719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "206: [D loss: 0.497595, acc: 0.787109]  [A loss: 0.748300, acc: 0.464844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "207: [D loss: 0.523994, acc: 0.691406]  [A loss: 1.670557, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "208: [D loss: 0.585782, acc: 0.664062]  [A loss: 0.622685, acc: 0.664062]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "209: [D loss: 0.622143, acc: 0.615234]  [A loss: 1.810760, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "210: [D loss: 0.595662, acc: 0.628906]  [A loss: 0.715364, acc: 0.531250]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "211: [D loss: 0.585964, acc: 0.623047]  [A loss: 1.518546, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "212: [D loss: 0.567856, acc: 0.701172]  [A loss: 0.756813, acc: 0.460938]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "213: [D loss: 0.560704, acc: 0.685547]  [A loss: 1.451164, acc: 0.027344]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "214: [D loss: 0.546832, acc: 0.708984]  [A loss: 0.784851, acc: 0.449219]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "215: [D loss: 0.549353, acc: 0.677734]  [A loss: 1.513903, acc: 0.015625]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "216: [D loss: 0.552865, acc: 0.714844]  [A loss: 0.707386, acc: 0.562500]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "217: [D loss: 0.561575, acc: 0.667969]  [A loss: 1.618322, acc: 0.003906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "218: [D loss: 0.579983, acc: 0.664062]  [A loss: 0.688135, acc: 0.562500]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "219: [D loss: 0.595436, acc: 0.623047]  [A loss: 1.796040, acc: 0.003906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "220: [D loss: 0.643845, acc: 0.615234]  [A loss: 0.564511, acc: 0.714844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "221: [D loss: 0.655650, acc: 0.599609]  [A loss: 1.621771, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "222: [D loss: 0.655177, acc: 0.583984]  [A loss: 0.752395, acc: 0.476562]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "223: [D loss: 0.592462, acc: 0.638672]  [A loss: 1.269100, acc: 0.058594]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "224: [D loss: 0.550489, acc: 0.736328]  [A loss: 0.897492, acc: 0.285156]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "225: [D loss: 0.572736, acc: 0.689453]  [A loss: 1.246897, acc: 0.058594]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "226: [D loss: 0.548470, acc: 0.753906]  [A loss: 0.855932, acc: 0.292969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "227: [D loss: 0.575328, acc: 0.724609]  [A loss: 1.324462, acc: 0.035156]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "228: [D loss: 0.556263, acc: 0.746094]  [A loss: 0.769406, acc: 0.441406]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "229: [D loss: 0.563032, acc: 0.677734]  [A loss: 1.576537, acc: 0.011719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "230: [D loss: 0.605218, acc: 0.636719]  [A loss: 0.533589, acc: 0.781250]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "231: [D loss: 0.674393, acc: 0.568359]  [A loss: 1.836318, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "232: [D loss: 0.719361, acc: 0.537109]  [A loss: 0.620799, acc: 0.621094]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "233: [D loss: 0.635840, acc: 0.597656]  [A loss: 1.259280, acc: 0.039062]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "234: [D loss: 0.583363, acc: 0.689453]  [A loss: 0.837651, acc: 0.343750]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "235: [D loss: 0.554441, acc: 0.740234]  [A loss: 1.061095, acc: 0.121094]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "236: [D loss: 0.577673, acc: 0.740234]  [A loss: 0.821421, acc: 0.359375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "237: [D loss: 0.614034, acc: 0.662109]  [A loss: 1.172635, acc: 0.070312]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "238: [D loss: 0.661018, acc: 0.562500]  [A loss: 0.788684, acc: 0.429688]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "239: [D loss: 0.700967, acc: 0.556641]  [A loss: 1.266829, acc: 0.046875]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "240: [D loss: 0.635079, acc: 0.628906]  [A loss: 0.851966, acc: 0.335938]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "241: [D loss: 0.606543, acc: 0.648438]  [A loss: 1.647539, acc: 0.019531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "242: [D loss: 0.631574, acc: 0.623047]  [A loss: 0.600549, acc: 0.675781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "243: [D loss: 0.659046, acc: 0.587891]  [A loss: 1.624113, acc: 0.007812]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "244: [D loss: 0.680410, acc: 0.558594]  [A loss: 0.681404, acc: 0.589844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "245: [D loss: 0.648833, acc: 0.589844]  [A loss: 1.196909, acc: 0.070312]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "246: [D loss: 0.596918, acc: 0.693359]  [A loss: 0.778587, acc: 0.398438]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "247: [D loss: 0.609026, acc: 0.679688]  [A loss: 1.203781, acc: 0.042969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "248: [D loss: 0.607904, acc: 0.671875]  [A loss: 0.727869, acc: 0.484375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "249: [D loss: 0.593061, acc: 0.673828]  [A loss: 1.199376, acc: 0.054688]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "250: [D loss: 0.601370, acc: 0.689453]  [A loss: 0.733248, acc: 0.449219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "251: [D loss: 0.589388, acc: 0.658203]  [A loss: 1.323345, acc: 0.023438]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "252: [D loss: 0.592896, acc: 0.667969]  [A loss: 0.676295, acc: 0.589844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "253: [D loss: 0.607385, acc: 0.625000]  [A loss: 1.457868, acc: 0.011719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "254: [D loss: 0.628809, acc: 0.619141]  [A loss: 0.640458, acc: 0.636719]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "255: [D loss: 0.612858, acc: 0.613281]  [A loss: 1.302363, acc: 0.007812]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "256: [D loss: 0.581033, acc: 0.669922]  [A loss: 0.671330, acc: 0.589844]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "257: [D loss: 0.609332, acc: 0.634766]  [A loss: 1.359995, acc: 0.007812]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "258: [D loss: 0.601352, acc: 0.640625]  [A loss: 0.651337, acc: 0.601562]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "259: [D loss: 0.621291, acc: 0.646484]  [A loss: 1.316903, acc: 0.015625]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "260: [D loss: 0.634988, acc: 0.611328]  [A loss: 0.627771, acc: 0.652344]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "261: [D loss: 0.633433, acc: 0.609375]  [A loss: 1.210579, acc: 0.027344]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "262: [D loss: 0.627620, acc: 0.636719]  [A loss: 0.683642, acc: 0.511719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "263: [D loss: 0.612540, acc: 0.648438]  [A loss: 1.163387, acc: 0.035156]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "264: [D loss: 0.591815, acc: 0.685547]  [A loss: 0.750880, acc: 0.449219]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "265: [D loss: 0.589623, acc: 0.716797]  [A loss: 1.138588, acc: 0.035156]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "266: [D loss: 0.608481, acc: 0.648438]  [A loss: 0.580763, acc: 0.734375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "267: [D loss: 0.620332, acc: 0.609375]  [A loss: 1.454727, acc: 0.003906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "268: [D loss: 0.655364, acc: 0.582031]  [A loss: 0.594588, acc: 0.683594]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "269: [D loss: 0.660649, acc: 0.572266]  [A loss: 1.287682, acc: 0.007812]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "270: [D loss: 0.634310, acc: 0.593750]  [A loss: 0.707831, acc: 0.515625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "271: [D loss: 0.613949, acc: 0.636719]  [A loss: 1.144566, acc: 0.035156]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "272: [D loss: 0.598012, acc: 0.689453]  [A loss: 0.760322, acc: 0.457031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "273: [D loss: 0.587119, acc: 0.689453]  [A loss: 1.156066, acc: 0.062500]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "274: [D loss: 0.610690, acc: 0.646484]  [A loss: 0.653253, acc: 0.609375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "275: [D loss: 0.609273, acc: 0.636719]  [A loss: 1.310441, acc: 0.023438]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "276: [D loss: 0.635095, acc: 0.613281]  [A loss: 0.621299, acc: 0.718750]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "277: [D loss: 0.647910, acc: 0.574219]  [A loss: 1.281875, acc: 0.031250]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "278: [D loss: 0.626665, acc: 0.599609]  [A loss: 0.660581, acc: 0.617188]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "279: [D loss: 0.622338, acc: 0.632812]  [A loss: 1.218922, acc: 0.011719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "280: [D loss: 0.633013, acc: 0.626953]  [A loss: 0.700156, acc: 0.515625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "281: [D loss: 0.611401, acc: 0.660156]  [A loss: 1.076425, acc: 0.062500]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "282: [D loss: 0.610855, acc: 0.658203]  [A loss: 0.739425, acc: 0.449219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "283: [D loss: 0.604645, acc: 0.656250]  [A loss: 1.182288, acc: 0.042969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "284: [D loss: 0.607099, acc: 0.689453]  [A loss: 0.626970, acc: 0.667969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "285: [D loss: 0.636281, acc: 0.597656]  [A loss: 1.317633, acc: 0.015625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "286: [D loss: 0.629593, acc: 0.619141]  [A loss: 0.621089, acc: 0.636719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "287: [D loss: 0.670703, acc: 0.574219]  [A loss: 1.294127, acc: 0.015625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "288: [D loss: 0.630159, acc: 0.628906]  [A loss: 0.639692, acc: 0.628906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "289: [D loss: 0.653361, acc: 0.587891]  [A loss: 1.196003, acc: 0.023438]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "290: [D loss: 0.626239, acc: 0.625000]  [A loss: 0.731302, acc: 0.503906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "291: [D loss: 0.596110, acc: 0.675781]  [A loss: 1.070610, acc: 0.066406]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "292: [D loss: 0.613162, acc: 0.664062]  [A loss: 0.796210, acc: 0.355469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "293: [D loss: 0.582028, acc: 0.710938]  [A loss: 1.145650, acc: 0.050781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "294: [D loss: 0.597455, acc: 0.658203]  [A loss: 0.651851, acc: 0.601562]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "295: [D loss: 0.623754, acc: 0.619141]  [A loss: 1.360095, acc: 0.019531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "296: [D loss: 0.658662, acc: 0.568359]  [A loss: 0.529767, acc: 0.796875]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "297: [D loss: 0.677804, acc: 0.550781]  [A loss: 1.299180, acc: 0.011719]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "298: [D loss: 0.672258, acc: 0.578125]  [A loss: 0.664905, acc: 0.605469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "299: [D loss: 0.641111, acc: 0.605469]  [A loss: 1.092462, acc: 0.062500]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "300: [D loss: 0.620825, acc: 0.654297]  [A loss: 0.745683, acc: 0.441406]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "301: [D loss: 0.606563, acc: 0.675781]  [A loss: 1.023205, acc: 0.078125]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "302: [D loss: 0.619042, acc: 0.666016]  [A loss: 0.763028, acc: 0.437500]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "303: [D loss: 0.619159, acc: 0.650391]  [A loss: 1.099937, acc: 0.093750]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "304: [D loss: 0.626332, acc: 0.634766]  [A loss: 0.720987, acc: 0.507812]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "305: [D loss: 0.630424, acc: 0.611328]  [A loss: 1.329578, acc: 0.015625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "306: [D loss: 0.658752, acc: 0.587891]  [A loss: 0.576815, acc: 0.734375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "307: [D loss: 0.649726, acc: 0.611328]  [A loss: 1.179332, acc: 0.050781]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "308: [D loss: 0.655164, acc: 0.593750]  [A loss: 0.684369, acc: 0.527344]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "309: [D loss: 0.695485, acc: 0.556641]  [A loss: 1.057167, acc: 0.078125]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "310: [D loss: 0.611529, acc: 0.677734]  [A loss: 0.662348, acc: 0.562500]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "311: [D loss: 0.631435, acc: 0.630859]  [A loss: 1.030254, acc: 0.109375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "312: [D loss: 0.624388, acc: 0.646484]  [A loss: 0.662892, acc: 0.597656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "313: [D loss: 0.616239, acc: 0.652344]  [A loss: 1.055307, acc: 0.117188]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "314: [D loss: 0.622241, acc: 0.656250]  [A loss: 0.760543, acc: 0.457031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "315: [D loss: 0.637543, acc: 0.626953]  [A loss: 1.210871, acc: 0.050781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "316: [D loss: 0.619076, acc: 0.650391]  [A loss: 0.565804, acc: 0.738281]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "317: [D loss: 0.668320, acc: 0.583984]  [A loss: 1.454298, acc: 0.007812]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "318: [D loss: 0.723097, acc: 0.527344]  [A loss: 0.588455, acc: 0.730469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "319: [D loss: 0.682078, acc: 0.556641]  [A loss: 1.080550, acc: 0.039062]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "320: [D loss: 0.623392, acc: 0.648438]  [A loss: 0.797011, acc: 0.324219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "321: [D loss: 0.612920, acc: 0.673828]  [A loss: 0.876191, acc: 0.230469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "322: [D loss: 0.611454, acc: 0.683594]  [A loss: 0.874918, acc: 0.222656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "323: [D loss: 0.611812, acc: 0.673828]  [A loss: 0.849472, acc: 0.285156]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "324: [D loss: 0.587041, acc: 0.730469]  [A loss: 0.846936, acc: 0.273438]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "325: [D loss: 0.617329, acc: 0.656250]  [A loss: 0.944864, acc: 0.175781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "326: [D loss: 0.610823, acc: 0.695312]  [A loss: 0.883949, acc: 0.257812]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "327: [D loss: 0.608098, acc: 0.675781]  [A loss: 0.908890, acc: 0.218750]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "328: [D loss: 0.622840, acc: 0.685547]  [A loss: 0.884345, acc: 0.246094]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "329: [D loss: 0.608585, acc: 0.687500]  [A loss: 0.904680, acc: 0.250000]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "330: [D loss: 0.602204, acc: 0.677734]  [A loss: 0.977527, acc: 0.187500]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "331: [D loss: 0.589803, acc: 0.705078]  [A loss: 0.713612, acc: 0.472656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "332: [D loss: 0.619792, acc: 0.640625]  [A loss: 1.547519, acc: 0.011719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "333: [D loss: 0.715438, acc: 0.556641]  [A loss: 0.414826, acc: 0.925781]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "334: [D loss: 0.830624, acc: 0.500000]  [A loss: 1.335952, acc: 0.011719]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "335: [D loss: 0.679011, acc: 0.552734]  [A loss: 0.791226, acc: 0.363281]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "336: [D loss: 0.619028, acc: 0.660156]  [A loss: 0.889634, acc: 0.187500]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "337: [D loss: 0.628800, acc: 0.656250]  [A loss: 0.854118, acc: 0.277344]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "338: [D loss: 0.626277, acc: 0.646484]  [A loss: 0.914852, acc: 0.199219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "339: [D loss: 0.606649, acc: 0.687500]  [A loss: 0.848625, acc: 0.304688]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "340: [D loss: 0.598577, acc: 0.712891]  [A loss: 0.910110, acc: 0.230469]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "341: [D loss: 0.620720, acc: 0.656250]  [A loss: 0.874641, acc: 0.226562]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "342: [D loss: 0.615617, acc: 0.687500]  [A loss: 0.904715, acc: 0.226562]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "343: [D loss: 0.632454, acc: 0.642578]  [A loss: 0.842242, acc: 0.289062]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "344: [D loss: 0.620251, acc: 0.648438]  [A loss: 1.052299, acc: 0.121094]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "345: [D loss: 0.607345, acc: 0.681641]  [A loss: 0.630194, acc: 0.652344]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "346: [D loss: 0.617658, acc: 0.636719]  [A loss: 1.429625, acc: 0.019531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "347: [D loss: 0.693710, acc: 0.572266]  [A loss: 0.418905, acc: 0.925781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "348: [D loss: 0.739323, acc: 0.531250]  [A loss: 1.274956, acc: 0.003906]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "349: [D loss: 0.695888, acc: 0.544922]  [A loss: 0.735380, acc: 0.472656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "350: [D loss: 0.634420, acc: 0.638672]  [A loss: 0.946301, acc: 0.160156]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "351: [D loss: 0.618811, acc: 0.679688]  [A loss: 0.788177, acc: 0.355469]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "352: [D loss: 0.614257, acc: 0.687500]  [A loss: 0.941056, acc: 0.136719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "353: [D loss: 0.619799, acc: 0.660156]  [A loss: 0.819548, acc: 0.347656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "354: [D loss: 0.618871, acc: 0.687500]  [A loss: 0.912298, acc: 0.218750]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "355: [D loss: 0.613788, acc: 0.673828]  [A loss: 0.834056, acc: 0.312500]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "356: [D loss: 0.626227, acc: 0.646484]  [A loss: 0.925067, acc: 0.199219]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "357: [D loss: 0.638952, acc: 0.650391]  [A loss: 0.759141, acc: 0.414062]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "358: [D loss: 0.600845, acc: 0.707031]  [A loss: 0.980145, acc: 0.156250]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "359: [D loss: 0.625891, acc: 0.634766]  [A loss: 0.707682, acc: 0.519531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "360: [D loss: 0.627209, acc: 0.640625]  [A loss: 1.276524, acc: 0.027344]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "361: [D loss: 0.688893, acc: 0.550781]  [A loss: 0.546794, acc: 0.750000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "362: [D loss: 0.702358, acc: 0.542969]  [A loss: 1.351096, acc: 0.015625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "363: [D loss: 0.698313, acc: 0.566406]  [A loss: 0.630542, acc: 0.589844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "364: [D loss: 0.654753, acc: 0.601562]  [A loss: 1.076046, acc: 0.070312]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "365: [D loss: 0.628862, acc: 0.642578]  [A loss: 0.751101, acc: 0.429688]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "366: [D loss: 0.625850, acc: 0.666016]  [A loss: 0.904687, acc: 0.203125]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "367: [D loss: 0.633922, acc: 0.652344]  [A loss: 0.814617, acc: 0.289062]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "368: [D loss: 0.623800, acc: 0.689453]  [A loss: 0.905858, acc: 0.199219]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "369: [D loss: 0.638676, acc: 0.638672]  [A loss: 0.786763, acc: 0.378906]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "370: [D loss: 0.625636, acc: 0.677734]  [A loss: 0.922792, acc: 0.214844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "371: [D loss: 0.623830, acc: 0.673828]  [A loss: 0.811480, acc: 0.378906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "372: [D loss: 0.625858, acc: 0.666016]  [A loss: 0.991212, acc: 0.152344]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "373: [D loss: 0.631210, acc: 0.654297]  [A loss: 0.725062, acc: 0.464844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "374: [D loss: 0.627834, acc: 0.630859]  [A loss: 1.157024, acc: 0.046875]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "375: [D loss: 0.646882, acc: 0.607422]  [A loss: 0.531378, acc: 0.808594]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "376: [D loss: 0.686306, acc: 0.552734]  [A loss: 1.356158, acc: 0.019531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "377: [D loss: 0.706742, acc: 0.541016]  [A loss: 0.655220, acc: 0.601562]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "378: [D loss: 0.659860, acc: 0.578125]  [A loss: 0.993263, acc: 0.109375]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "379: [D loss: 0.628790, acc: 0.632812]  [A loss: 0.731285, acc: 0.460938]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "380: [D loss: 0.629027, acc: 0.644531]  [A loss: 0.967488, acc: 0.125000]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "381: [D loss: 0.631160, acc: 0.658203]  [A loss: 0.740320, acc: 0.449219]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "382: [D loss: 0.630460, acc: 0.632812]  [A loss: 1.048536, acc: 0.101562]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "383: [D loss: 0.627516, acc: 0.628906]  [A loss: 0.766501, acc: 0.417969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "384: [D loss: 0.620347, acc: 0.658203]  [A loss: 0.956239, acc: 0.175781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "385: [D loss: 0.631643, acc: 0.632812]  [A loss: 0.800156, acc: 0.367188]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "386: [D loss: 0.612043, acc: 0.679688]  [A loss: 0.983486, acc: 0.167969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "387: [D loss: 0.624390, acc: 0.669922]  [A loss: 0.737661, acc: 0.464844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "388: [D loss: 0.653297, acc: 0.605469]  [A loss: 1.132815, acc: 0.050781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "389: [D loss: 0.656094, acc: 0.601562]  [A loss: 0.632347, acc: 0.648438]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "390: [D loss: 0.666959, acc: 0.560547]  [A loss: 1.323199, acc: 0.011719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "391: [D loss: 0.697936, acc: 0.558594]  [A loss: 0.551200, acc: 0.781250]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "392: [D loss: 0.691219, acc: 0.542969]  [A loss: 1.133982, acc: 0.058594]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "393: [D loss: 0.677426, acc: 0.572266]  [A loss: 0.752272, acc: 0.398438]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "394: [D loss: 0.630815, acc: 0.634766]  [A loss: 0.901879, acc: 0.171875]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "395: [D loss: 0.617045, acc: 0.658203]  [A loss: 0.800991, acc: 0.343750]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "396: [D loss: 0.611883, acc: 0.695312]  [A loss: 0.898249, acc: 0.222656]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "397: [D loss: 0.640918, acc: 0.623047]  [A loss: 0.827156, acc: 0.296875]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "398: [D loss: 0.632253, acc: 0.654297]  [A loss: 0.883306, acc: 0.246094]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "399: [D loss: 0.644196, acc: 0.621094]  [A loss: 0.801410, acc: 0.324219]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "400: [D loss: 0.631882, acc: 0.648438]  [A loss: 0.870754, acc: 0.214844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "401: [D loss: 0.618303, acc: 0.679688]  [A loss: 0.890379, acc: 0.273438]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "402: [D loss: 0.632643, acc: 0.646484]  [A loss: 0.877728, acc: 0.230469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "403: [D loss: 0.619740, acc: 0.660156]  [A loss: 0.907628, acc: 0.210938]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "404: [D loss: 0.604559, acc: 0.685547]  [A loss: 0.790689, acc: 0.351562]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "405: [D loss: 0.630459, acc: 0.646484]  [A loss: 1.110216, acc: 0.089844]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "406: [D loss: 0.626765, acc: 0.621094]  [A loss: 0.559696, acc: 0.730469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "407: [D loss: 0.692228, acc: 0.544922]  [A loss: 1.517497, acc: 0.000000]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "408: [D loss: 0.755231, acc: 0.525391]  [A loss: 0.613300, acc: 0.664062]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "409: [D loss: 0.661610, acc: 0.564453]  [A loss: 1.038964, acc: 0.082031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "410: [D loss: 0.629903, acc: 0.638672]  [A loss: 0.787227, acc: 0.351562]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "411: [D loss: 0.630302, acc: 0.666016]  [A loss: 0.880963, acc: 0.246094]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "412: [D loss: 0.604401, acc: 0.714844]  [A loss: 0.814154, acc: 0.351562]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "413: [D loss: 0.647904, acc: 0.611328]  [A loss: 0.980619, acc: 0.160156]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "414: [D loss: 0.623542, acc: 0.640625]  [A loss: 0.807765, acc: 0.339844]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "415: [D loss: 0.632026, acc: 0.664062]  [A loss: 0.919585, acc: 0.218750]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "416: [D loss: 0.613494, acc: 0.667969]  [A loss: 0.846563, acc: 0.328125]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "417: [D loss: 0.598371, acc: 0.707031]  [A loss: 0.848704, acc: 0.308594]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "418: [D loss: 0.623416, acc: 0.667969]  [A loss: 1.004332, acc: 0.140625]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "419: [D loss: 0.603111, acc: 0.707031]  [A loss: 0.726256, acc: 0.480469]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "420: [D loss: 0.643515, acc: 0.628906]  [A loss: 1.353791, acc: 0.015625]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "421: [D loss: 0.694171, acc: 0.560547]  [A loss: 0.552503, acc: 0.753906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "422: [D loss: 0.670211, acc: 0.560547]  [A loss: 1.286248, acc: 0.027344]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "423: [D loss: 0.662124, acc: 0.585938]  [A loss: 0.769903, acc: 0.394531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "424: [D loss: 0.617569, acc: 0.644531]  [A loss: 0.954354, acc: 0.152344]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "425: [D loss: 0.608376, acc: 0.687500]  [A loss: 0.808286, acc: 0.347656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "426: [D loss: 0.634554, acc: 0.650391]  [A loss: 0.963196, acc: 0.187500]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "427: [D loss: 0.610586, acc: 0.685547]  [A loss: 0.839279, acc: 0.289062]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "428: [D loss: 0.624392, acc: 0.664062]  [A loss: 0.996107, acc: 0.152344]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "429: [D loss: 0.625154, acc: 0.658203]  [A loss: 0.745904, acc: 0.472656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "430: [D loss: 0.637793, acc: 0.625000]  [A loss: 1.082866, acc: 0.085938]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "431: [D loss: 0.634381, acc: 0.634766]  [A loss: 0.696135, acc: 0.519531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "432: [D loss: 0.656100, acc: 0.623047]  [A loss: 1.186934, acc: 0.039062]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "433: [D loss: 0.677136, acc: 0.585938]  [A loss: 0.640767, acc: 0.605469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "434: [D loss: 0.634601, acc: 0.613281]  [A loss: 1.112106, acc: 0.050781]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "435: [D loss: 0.657301, acc: 0.609375]  [A loss: 0.731375, acc: 0.460938]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "436: [D loss: 0.628505, acc: 0.644531]  [A loss: 1.003384, acc: 0.128906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "437: [D loss: 0.649062, acc: 0.619141]  [A loss: 0.769863, acc: 0.378906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "438: [D loss: 0.640642, acc: 0.626953]  [A loss: 0.958080, acc: 0.144531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "439: [D loss: 0.612383, acc: 0.673828]  [A loss: 0.840191, acc: 0.281250]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "440: [D loss: 0.622403, acc: 0.640625]  [A loss: 0.928229, acc: 0.203125]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "441: [D loss: 0.619286, acc: 0.669922]  [A loss: 0.836380, acc: 0.304688]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "442: [D loss: 0.621499, acc: 0.677734]  [A loss: 0.975797, acc: 0.171875]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "443: [D loss: 0.648015, acc: 0.619141]  [A loss: 0.816099, acc: 0.332031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "444: [D loss: 0.617096, acc: 0.675781]  [A loss: 0.980261, acc: 0.171875]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "445: [D loss: 0.622461, acc: 0.630859]  [A loss: 0.763395, acc: 0.394531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "446: [D loss: 0.629274, acc: 0.642578]  [A loss: 1.174260, acc: 0.089844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "447: [D loss: 0.668838, acc: 0.591797]  [A loss: 0.500377, acc: 0.820312]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "448: [D loss: 0.702213, acc: 0.558594]  [A loss: 1.306109, acc: 0.023438]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "449: [D loss: 0.713157, acc: 0.531250]  [A loss: 0.709413, acc: 0.484375]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "450: [D loss: 0.645350, acc: 0.623047]  [A loss: 0.931544, acc: 0.140625]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "451: [D loss: 0.610305, acc: 0.675781]  [A loss: 0.808652, acc: 0.355469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "452: [D loss: 0.632744, acc: 0.644531]  [A loss: 0.849094, acc: 0.265625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "453: [D loss: 0.618392, acc: 0.671875]  [A loss: 0.852368, acc: 0.269531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "454: [D loss: 0.628477, acc: 0.656250]  [A loss: 0.910051, acc: 0.238281]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "455: [D loss: 0.619324, acc: 0.658203]  [A loss: 0.867772, acc: 0.257812]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "456: [D loss: 0.626874, acc: 0.669922]  [A loss: 0.972918, acc: 0.183594]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "457: [D loss: 0.618623, acc: 0.673828]  [A loss: 0.707837, acc: 0.550781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "458: [D loss: 0.626633, acc: 0.638672]  [A loss: 1.161664, acc: 0.074219]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "459: [D loss: 0.652713, acc: 0.599609]  [A loss: 0.622575, acc: 0.656250]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "460: [D loss: 0.695028, acc: 0.583984]  [A loss: 1.248934, acc: 0.042969]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "461: [D loss: 0.675446, acc: 0.566406]  [A loss: 0.726697, acc: 0.460938]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "462: [D loss: 0.633324, acc: 0.625000]  [A loss: 0.948971, acc: 0.148438]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "463: [D loss: 0.629810, acc: 0.634766]  [A loss: 0.738899, acc: 0.449219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "464: [D loss: 0.620619, acc: 0.664062]  [A loss: 0.994733, acc: 0.144531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "465: [D loss: 0.660926, acc: 0.582031]  [A loss: 0.735528, acc: 0.441406]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "466: [D loss: 0.627242, acc: 0.642578]  [A loss: 1.016992, acc: 0.109375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "467: [D loss: 0.627571, acc: 0.679688]  [A loss: 0.778196, acc: 0.394531]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "468: [D loss: 0.641666, acc: 0.638672]  [A loss: 1.051770, acc: 0.148438]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "469: [D loss: 0.659234, acc: 0.609375]  [A loss: 0.699737, acc: 0.515625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "470: [D loss: 0.631158, acc: 0.630859]  [A loss: 1.067574, acc: 0.082031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "471: [D loss: 0.638403, acc: 0.634766]  [A loss: 0.687822, acc: 0.558594]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "472: [D loss: 0.667634, acc: 0.603516]  [A loss: 1.030103, acc: 0.109375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "473: [D loss: 0.633106, acc: 0.632812]  [A loss: 0.717861, acc: 0.464844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "474: [D loss: 0.628460, acc: 0.646484]  [A loss: 1.016454, acc: 0.097656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "475: [D loss: 0.621749, acc: 0.660156]  [A loss: 0.799176, acc: 0.351562]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "476: [D loss: 0.621767, acc: 0.652344]  [A loss: 1.003165, acc: 0.148438]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "477: [D loss: 0.618414, acc: 0.650391]  [A loss: 0.738597, acc: 0.464844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "478: [D loss: 0.647178, acc: 0.632812]  [A loss: 1.088543, acc: 0.070312]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "479: [D loss: 0.648378, acc: 0.617188]  [A loss: 0.751515, acc: 0.445312]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "480: [D loss: 0.664860, acc: 0.587891]  [A loss: 1.025676, acc: 0.121094]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "481: [D loss: 0.636684, acc: 0.628906]  [A loss: 0.737128, acc: 0.453125]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "482: [D loss: 0.629158, acc: 0.646484]  [A loss: 1.013677, acc: 0.132812]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "483: [D loss: 0.628736, acc: 0.646484]  [A loss: 0.727057, acc: 0.464844]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "484: [D loss: 0.626483, acc: 0.632812]  [A loss: 1.063944, acc: 0.117188]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "485: [D loss: 0.638669, acc: 0.638672]  [A loss: 0.753432, acc: 0.437500]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "486: [D loss: 0.620517, acc: 0.671875]  [A loss: 1.045018, acc: 0.117188]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "487: [D loss: 0.632121, acc: 0.636719]  [A loss: 0.748943, acc: 0.488281]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "488: [D loss: 0.641774, acc: 0.628906]  [A loss: 1.069282, acc: 0.105469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "489: [D loss: 0.642438, acc: 0.623047]  [A loss: 0.696744, acc: 0.519531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "490: [D loss: 0.649474, acc: 0.611328]  [A loss: 1.120886, acc: 0.125000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "491: [D loss: 0.644233, acc: 0.615234]  [A loss: 0.678083, acc: 0.542969]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "492: [D loss: 0.644916, acc: 0.634766]  [A loss: 1.089840, acc: 0.078125]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "493: [D loss: 0.643574, acc: 0.617188]  [A loss: 0.769769, acc: 0.417969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "494: [D loss: 0.641178, acc: 0.638672]  [A loss: 1.035274, acc: 0.105469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "495: [D loss: 0.628695, acc: 0.625000]  [A loss: 0.782165, acc: 0.355469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "496: [D loss: 0.583043, acc: 0.718750]  [A loss: 0.930509, acc: 0.226562]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "497: [D loss: 0.637521, acc: 0.648438]  [A loss: 0.823500, acc: 0.363281]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "498: [D loss: 0.623348, acc: 0.652344]  [A loss: 0.936307, acc: 0.226562]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "499: [D loss: 0.635288, acc: 0.623047]  [A loss: 0.894192, acc: 0.253906]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "500: [D loss: 0.621709, acc: 0.646484]  [A loss: 0.892833, acc: 0.285156]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "501: [D loss: 0.640748, acc: 0.628906]  [A loss: 0.928098, acc: 0.191406]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "502: [D loss: 0.614763, acc: 0.671875]  [A loss: 0.808107, acc: 0.300781]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "503: [D loss: 0.607640, acc: 0.693359]  [A loss: 0.989676, acc: 0.152344]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "504: [D loss: 0.650793, acc: 0.603516]  [A loss: 0.697609, acc: 0.558594]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "505: [D loss: 0.640373, acc: 0.621094]  [A loss: 1.210674, acc: 0.062500]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "506: [D loss: 0.638162, acc: 0.623047]  [A loss: 0.618442, acc: 0.675781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "507: [D loss: 0.658241, acc: 0.587891]  [A loss: 1.275335, acc: 0.031250]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "508: [D loss: 0.646374, acc: 0.591797]  [A loss: 0.677923, acc: 0.574219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "509: [D loss: 0.641661, acc: 0.628906]  [A loss: 1.047695, acc: 0.085938]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "510: [D loss: 0.621507, acc: 0.646484]  [A loss: 0.855769, acc: 0.312500]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "511: [D loss: 0.613719, acc: 0.675781]  [A loss: 0.932123, acc: 0.191406]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "512: [D loss: 0.632768, acc: 0.664062]  [A loss: 0.882990, acc: 0.261719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "513: [D loss: 0.616460, acc: 0.662109]  [A loss: 0.857816, acc: 0.296875]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "514: [D loss: 0.613576, acc: 0.697266]  [A loss: 0.906374, acc: 0.253906]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "515: [D loss: 0.604441, acc: 0.675781]  [A loss: 0.879971, acc: 0.292969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "516: [D loss: 0.624622, acc: 0.652344]  [A loss: 0.926828, acc: 0.234375]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "517: [D loss: 0.620932, acc: 0.667969]  [A loss: 1.005439, acc: 0.175781]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "518: [D loss: 0.622715, acc: 0.656250]  [A loss: 0.846472, acc: 0.316406]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "519: [D loss: 0.602060, acc: 0.701172]  [A loss: 1.142575, acc: 0.078125]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "520: [D loss: 0.649332, acc: 0.603516]  [A loss: 0.634335, acc: 0.628906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "521: [D loss: 0.671015, acc: 0.566406]  [A loss: 1.490911, acc: 0.011719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "522: [D loss: 0.741380, acc: 0.521484]  [A loss: 0.625510, acc: 0.625000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "523: [D loss: 0.668122, acc: 0.568359]  [A loss: 1.124261, acc: 0.093750]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "524: [D loss: 0.646994, acc: 0.609375]  [A loss: 0.825885, acc: 0.312500]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "525: [D loss: 0.601678, acc: 0.669922]  [A loss: 0.874320, acc: 0.265625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "526: [D loss: 0.593731, acc: 0.693359]  [A loss: 0.894963, acc: 0.296875]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "527: [D loss: 0.621465, acc: 0.638672]  [A loss: 0.860329, acc: 0.308594]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "528: [D loss: 0.598465, acc: 0.685547]  [A loss: 0.908668, acc: 0.261719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "529: [D loss: 0.619447, acc: 0.656250]  [A loss: 0.908809, acc: 0.246094]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "530: [D loss: 0.637519, acc: 0.630859]  [A loss: 0.893320, acc: 0.265625]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "531: [D loss: 0.631915, acc: 0.648438]  [A loss: 0.934157, acc: 0.207031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "532: [D loss: 0.635687, acc: 0.648438]  [A loss: 0.781845, acc: 0.414062]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "533: [D loss: 0.630547, acc: 0.634766]  [A loss: 0.986673, acc: 0.234375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "534: [D loss: 0.637431, acc: 0.623047]  [A loss: 0.781560, acc: 0.398438]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "535: [D loss: 0.614750, acc: 0.679688]  [A loss: 0.978327, acc: 0.203125]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "536: [D loss: 0.609272, acc: 0.693359]  [A loss: 0.750246, acc: 0.457031]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "537: [D loss: 0.607790, acc: 0.648438]  [A loss: 1.160279, acc: 0.082031]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "538: [D loss: 0.630070, acc: 0.634766]  [A loss: 0.677993, acc: 0.558594]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "539: [D loss: 0.624936, acc: 0.654297]  [A loss: 1.256494, acc: 0.039062]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "540: [D loss: 0.657853, acc: 0.609375]  [A loss: 0.664346, acc: 0.585938]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "541: [D loss: 0.649782, acc: 0.605469]  [A loss: 1.145175, acc: 0.078125]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "542: [D loss: 0.650567, acc: 0.605469]  [A loss: 0.746631, acc: 0.468750]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "543: [D loss: 0.633427, acc: 0.640625]  [A loss: 1.032708, acc: 0.101562]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "544: [D loss: 0.637550, acc: 0.628906]  [A loss: 0.749552, acc: 0.453125]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "545: [D loss: 0.620863, acc: 0.669922]  [A loss: 1.046658, acc: 0.144531]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "546: [D loss: 0.614564, acc: 0.681641]  [A loss: 0.768704, acc: 0.425781]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "547: [D loss: 0.632853, acc: 0.658203]  [A loss: 1.021086, acc: 0.167969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "548: [D loss: 0.641693, acc: 0.628906]  [A loss: 0.836386, acc: 0.324219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "549: [D loss: 0.616849, acc: 0.669922]  [A loss: 0.888053, acc: 0.277344]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "550: [D loss: 0.607493, acc: 0.681641]  [A loss: 0.912259, acc: 0.292969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "551: [D loss: 0.635760, acc: 0.642578]  [A loss: 0.959759, acc: 0.210938]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "552: [D loss: 0.615328, acc: 0.656250]  [A loss: 0.855608, acc: 0.320312]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "553: [D loss: 0.650323, acc: 0.580078]  [A loss: 0.994368, acc: 0.160156]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "554: [D loss: 0.636054, acc: 0.656250]  [A loss: 0.815715, acc: 0.355469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "555: [D loss: 0.631916, acc: 0.640625]  [A loss: 1.061849, acc: 0.136719]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "556: [D loss: 0.631666, acc: 0.642578]  [A loss: 0.704994, acc: 0.539062]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "557: [D loss: 0.638444, acc: 0.621094]  [A loss: 1.262487, acc: 0.058594]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "558: [D loss: 0.632163, acc: 0.619141]  [A loss: 0.718083, acc: 0.488281]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "559: [D loss: 0.657318, acc: 0.611328]  [A loss: 1.138615, acc: 0.082031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "560: [D loss: 0.629553, acc: 0.636719]  [A loss: 0.766456, acc: 0.433594]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "561: [D loss: 0.639688, acc: 0.636719]  [A loss: 1.031255, acc: 0.144531]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "562: [D loss: 0.640621, acc: 0.638672]  [A loss: 0.808485, acc: 0.371094]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "563: [D loss: 0.631934, acc: 0.640625]  [A loss: 0.940712, acc: 0.195312]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "564: [D loss: 0.598696, acc: 0.712891]  [A loss: 0.880599, acc: 0.312500]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "565: [D loss: 0.635741, acc: 0.634766]  [A loss: 1.015646, acc: 0.171875]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "566: [D loss: 0.621485, acc: 0.652344]  [A loss: 0.897882, acc: 0.277344]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "567: [D loss: 0.602477, acc: 0.691406]  [A loss: 0.947102, acc: 0.242188]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "568: [D loss: 0.606936, acc: 0.689453]  [A loss: 0.961843, acc: 0.238281]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "569: [D loss: 0.629260, acc: 0.640625]  [A loss: 0.853649, acc: 0.324219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "570: [D loss: 0.613450, acc: 0.673828]  [A loss: 1.069453, acc: 0.160156]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "571: [D loss: 0.607958, acc: 0.666016]  [A loss: 0.729695, acc: 0.492188]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "572: [D loss: 0.624512, acc: 0.619141]  [A loss: 1.341429, acc: 0.039062]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "573: [D loss: 0.655123, acc: 0.623047]  [A loss: 0.661792, acc: 0.574219]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "574: [D loss: 0.647293, acc: 0.605469]  [A loss: 1.146568, acc: 0.093750]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "575: [D loss: 0.634921, acc: 0.609375]  [A loss: 0.771567, acc: 0.394531]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "576: [D loss: 0.620692, acc: 0.652344]  [A loss: 1.057043, acc: 0.117188]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "577: [D loss: 0.648227, acc: 0.632812]  [A loss: 0.805627, acc: 0.367188]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "578: [D loss: 0.611929, acc: 0.675781]  [A loss: 0.976614, acc: 0.222656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "579: [D loss: 0.633017, acc: 0.644531]  [A loss: 0.880873, acc: 0.281250]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "580: [D loss: 0.600368, acc: 0.679688]  [A loss: 0.911479, acc: 0.250000]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "581: [D loss: 0.611348, acc: 0.671875]  [A loss: 0.964174, acc: 0.214844]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "582: [D loss: 0.633835, acc: 0.644531]  [A loss: 0.919419, acc: 0.257812]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "583: [D loss: 0.629133, acc: 0.677734]  [A loss: 0.898179, acc: 0.269531]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "584: [D loss: 0.617023, acc: 0.675781]  [A loss: 1.080212, acc: 0.117188]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "585: [D loss: 0.621330, acc: 0.664062]  [A loss: 0.732338, acc: 0.460938]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "586: [D loss: 0.660063, acc: 0.607422]  [A loss: 1.222931, acc: 0.078125]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "587: [D loss: 0.673360, acc: 0.583984]  [A loss: 0.651313, acc: 0.558594]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "588: [D loss: 0.659417, acc: 0.597656]  [A loss: 1.131960, acc: 0.078125]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "589: [D loss: 0.648561, acc: 0.621094]  [A loss: 0.808140, acc: 0.410156]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "590: [D loss: 0.621464, acc: 0.660156]  [A loss: 0.987640, acc: 0.175781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "591: [D loss: 0.620042, acc: 0.666016]  [A loss: 0.864792, acc: 0.261719]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "592: [D loss: 0.603181, acc: 0.679688]  [A loss: 0.875546, acc: 0.320312]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "593: [D loss: 0.611365, acc: 0.675781]  [A loss: 0.982861, acc: 0.175781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "594: [D loss: 0.598526, acc: 0.697266]  [A loss: 0.866552, acc: 0.312500]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "595: [D loss: 0.608381, acc: 0.667969]  [A loss: 1.112237, acc: 0.097656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "596: [D loss: 0.634378, acc: 0.652344]  [A loss: 0.812612, acc: 0.367188]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "597: [D loss: 0.612551, acc: 0.656250]  [A loss: 1.139292, acc: 0.109375]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "598: [D loss: 0.630039, acc: 0.630859]  [A loss: 0.661101, acc: 0.558594]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "599: [D loss: 0.660491, acc: 0.630859]  [A loss: 1.244745, acc: 0.039062]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "600: [D loss: 0.657891, acc: 0.595703]  [A loss: 0.730576, acc: 0.484375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "601: [D loss: 0.642480, acc: 0.621094]  [A loss: 1.049657, acc: 0.148438]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "602: [D loss: 0.619752, acc: 0.666016]  [A loss: 0.859370, acc: 0.328125]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "603: [D loss: 0.616819, acc: 0.669922]  [A loss: 0.938703, acc: 0.218750]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "604: [D loss: 0.635912, acc: 0.630859]  [A loss: 0.829199, acc: 0.332031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "605: [D loss: 0.616637, acc: 0.656250]  [A loss: 1.065513, acc: 0.125000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "606: [D loss: 0.611496, acc: 0.677734]  [A loss: 0.818968, acc: 0.363281]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "607: [D loss: 0.635798, acc: 0.642578]  [A loss: 1.116241, acc: 0.078125]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "608: [D loss: 0.632423, acc: 0.642578]  [A loss: 0.807762, acc: 0.375000]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "609: [D loss: 0.614319, acc: 0.634766]  [A loss: 0.946499, acc: 0.195312]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "610: [D loss: 0.613871, acc: 0.687500]  [A loss: 0.914997, acc: 0.285156]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "611: [D loss: 0.599056, acc: 0.679688]  [A loss: 0.911644, acc: 0.269531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "612: [D loss: 0.625674, acc: 0.654297]  [A loss: 0.891689, acc: 0.289062]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "613: [D loss: 0.605925, acc: 0.685547]  [A loss: 1.108895, acc: 0.105469]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "614: [D loss: 0.630570, acc: 0.654297]  [A loss: 0.704454, acc: 0.527344]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "615: [D loss: 0.660687, acc: 0.617188]  [A loss: 1.259460, acc: 0.050781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "616: [D loss: 0.651696, acc: 0.615234]  [A loss: 0.734394, acc: 0.492188]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "617: [D loss: 0.619538, acc: 0.644531]  [A loss: 1.089173, acc: 0.109375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "618: [D loss: 0.621687, acc: 0.666016]  [A loss: 0.840308, acc: 0.296875]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "619: [D loss: 0.621269, acc: 0.636719]  [A loss: 1.001011, acc: 0.152344]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "620: [D loss: 0.638755, acc: 0.609375]  [A loss: 0.876403, acc: 0.281250]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "621: [D loss: 0.601923, acc: 0.693359]  [A loss: 0.905401, acc: 0.238281]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "622: [D loss: 0.610336, acc: 0.671875]  [A loss: 1.014925, acc: 0.187500]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "623: [D loss: 0.583582, acc: 0.716797]  [A loss: 0.890112, acc: 0.296875]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "624: [D loss: 0.610573, acc: 0.656250]  [A loss: 1.154345, acc: 0.105469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "625: [D loss: 0.655064, acc: 0.625000]  [A loss: 0.789180, acc: 0.371094]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "626: [D loss: 0.644663, acc: 0.623047]  [A loss: 1.218455, acc: 0.085938]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "627: [D loss: 0.643608, acc: 0.615234]  [A loss: 0.756558, acc: 0.453125]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "628: [D loss: 0.652687, acc: 0.605469]  [A loss: 1.086739, acc: 0.097656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "629: [D loss: 0.619020, acc: 0.650391]  [A loss: 0.783916, acc: 0.410156]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "630: [D loss: 0.631189, acc: 0.664062]  [A loss: 1.090795, acc: 0.113281]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "631: [D loss: 0.608140, acc: 0.673828]  [A loss: 0.846099, acc: 0.355469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "632: [D loss: 0.629216, acc: 0.654297]  [A loss: 1.031478, acc: 0.171875]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "633: [D loss: 0.611711, acc: 0.666016]  [A loss: 0.916752, acc: 0.253906]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "634: [D loss: 0.638044, acc: 0.642578]  [A loss: 0.967605, acc: 0.187500]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "635: [D loss: 0.622213, acc: 0.669922]  [A loss: 0.896768, acc: 0.312500]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "636: [D loss: 0.588692, acc: 0.693359]  [A loss: 0.942123, acc: 0.273438]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "637: [D loss: 0.626194, acc: 0.673828]  [A loss: 0.998994, acc: 0.187500]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "638: [D loss: 0.608220, acc: 0.679688]  [A loss: 0.828098, acc: 0.332031]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "639: [D loss: 0.606051, acc: 0.677734]  [A loss: 1.039643, acc: 0.191406]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "640: [D loss: 0.639978, acc: 0.628906]  [A loss: 0.843350, acc: 0.324219]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "641: [D loss: 0.621638, acc: 0.648438]  [A loss: 1.070439, acc: 0.136719]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "642: [D loss: 0.629832, acc: 0.660156]  [A loss: 0.793624, acc: 0.417969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "643: [D loss: 0.641704, acc: 0.601562]  [A loss: 1.218444, acc: 0.062500]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "644: [D loss: 0.631349, acc: 0.640625]  [A loss: 0.716447, acc: 0.503906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "645: [D loss: 0.640328, acc: 0.621094]  [A loss: 1.186134, acc: 0.093750]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "646: [D loss: 0.645701, acc: 0.621094]  [A loss: 0.784196, acc: 0.402344]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "647: [D loss: 0.625420, acc: 0.644531]  [A loss: 1.112159, acc: 0.097656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "648: [D loss: 0.633411, acc: 0.650391]  [A loss: 0.771303, acc: 0.433594]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "649: [D loss: 0.625642, acc: 0.632812]  [A loss: 1.068347, acc: 0.160156]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "650: [D loss: 0.628347, acc: 0.626953]  [A loss: 0.907580, acc: 0.273438]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "651: [D loss: 0.616892, acc: 0.677734]  [A loss: 1.070273, acc: 0.144531]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "652: [D loss: 0.599033, acc: 0.681641]  [A loss: 0.742261, acc: 0.464844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "653: [D loss: 0.642901, acc: 0.623047]  [A loss: 1.182970, acc: 0.117188]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "654: [D loss: 0.621982, acc: 0.644531]  [A loss: 0.755290, acc: 0.433594]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "655: [D loss: 0.642285, acc: 0.632812]  [A loss: 1.085712, acc: 0.136719]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "656: [D loss: 0.641526, acc: 0.632812]  [A loss: 0.782006, acc: 0.421875]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "657: [D loss: 0.628116, acc: 0.642578]  [A loss: 1.019018, acc: 0.179688]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "658: [D loss: 0.607704, acc: 0.666016]  [A loss: 0.819717, acc: 0.343750]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "659: [D loss: 0.621376, acc: 0.677734]  [A loss: 1.029739, acc: 0.160156]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "660: [D loss: 0.612083, acc: 0.660156]  [A loss: 0.805158, acc: 0.371094]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "661: [D loss: 0.621687, acc: 0.640625]  [A loss: 1.140552, acc: 0.113281]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "662: [D loss: 0.644005, acc: 0.619141]  [A loss: 0.701262, acc: 0.503906]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "663: [D loss: 0.613959, acc: 0.646484]  [A loss: 1.151917, acc: 0.105469]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "664: [D loss: 0.645836, acc: 0.603516]  [A loss: 0.744988, acc: 0.480469]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "665: [D loss: 0.621799, acc: 0.640625]  [A loss: 1.122217, acc: 0.085938]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "666: [D loss: 0.640291, acc: 0.623047]  [A loss: 0.830768, acc: 0.355469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "667: [D loss: 0.597730, acc: 0.681641]  [A loss: 1.021570, acc: 0.152344]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "668: [D loss: 0.617685, acc: 0.634766]  [A loss: 0.831216, acc: 0.343750]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "669: [D loss: 0.602196, acc: 0.695312]  [A loss: 1.015391, acc: 0.175781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "670: [D loss: 0.621549, acc: 0.664062]  [A loss: 0.876556, acc: 0.277344]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "671: [D loss: 0.614096, acc: 0.654297]  [A loss: 1.024778, acc: 0.152344]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "672: [D loss: 0.613510, acc: 0.667969]  [A loss: 0.867571, acc: 0.312500]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "673: [D loss: 0.612045, acc: 0.671875]  [A loss: 1.088090, acc: 0.136719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "674: [D loss: 0.586432, acc: 0.689453]  [A loss: 0.831489, acc: 0.363281]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "675: [D loss: 0.646403, acc: 0.656250]  [A loss: 1.145434, acc: 0.132812]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "676: [D loss: 0.604428, acc: 0.658203]  [A loss: 0.799450, acc: 0.398438]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "677: [D loss: 0.632343, acc: 0.666016]  [A loss: 1.275527, acc: 0.082031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "678: [D loss: 0.642839, acc: 0.638672]  [A loss: 0.740710, acc: 0.476562]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "679: [D loss: 0.604596, acc: 0.681641]  [A loss: 1.103450, acc: 0.160156]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "680: [D loss: 0.640045, acc: 0.648438]  [A loss: 0.810562, acc: 0.394531]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "681: [D loss: 0.612635, acc: 0.673828]  [A loss: 1.057161, acc: 0.179688]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "682: [D loss: 0.639355, acc: 0.621094]  [A loss: 0.832885, acc: 0.355469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "683: [D loss: 0.623548, acc: 0.662109]  [A loss: 1.037325, acc: 0.179688]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "684: [D loss: 0.615821, acc: 0.679688]  [A loss: 0.853731, acc: 0.332031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "685: [D loss: 0.634746, acc: 0.654297]  [A loss: 1.170933, acc: 0.101562]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "686: [D loss: 0.638587, acc: 0.646484]  [A loss: 0.778218, acc: 0.398438]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "687: [D loss: 0.637390, acc: 0.621094]  [A loss: 1.024593, acc: 0.167969]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "688: [D loss: 0.631611, acc: 0.650391]  [A loss: 0.860172, acc: 0.281250]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "689: [D loss: 0.598754, acc: 0.699219]  [A loss: 0.996410, acc: 0.183594]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "690: [D loss: 0.606918, acc: 0.708984]  [A loss: 0.877374, acc: 0.296875]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "691: [D loss: 0.610647, acc: 0.677734]  [A loss: 0.969841, acc: 0.226562]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "692: [D loss: 0.605441, acc: 0.667969]  [A loss: 0.893459, acc: 0.269531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "693: [D loss: 0.595663, acc: 0.695312]  [A loss: 1.033524, acc: 0.207031]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "694: [D loss: 0.617215, acc: 0.677734]  [A loss: 0.905465, acc: 0.300781]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "695: [D loss: 0.606192, acc: 0.658203]  [A loss: 1.074540, acc: 0.140625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "696: [D loss: 0.602064, acc: 0.683594]  [A loss: 0.809839, acc: 0.398438]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "697: [D loss: 0.635480, acc: 0.626953]  [A loss: 1.261779, acc: 0.050781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "698: [D loss: 0.662493, acc: 0.595703]  [A loss: 0.663354, acc: 0.574219]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "699: [D loss: 0.663374, acc: 0.589844]  [A loss: 1.250228, acc: 0.046875]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "700: [D loss: 0.656454, acc: 0.599609]  [A loss: 0.759669, acc: 0.464844]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "701: [D loss: 0.627033, acc: 0.648438]  [A loss: 1.046232, acc: 0.136719]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "702: [D loss: 0.601945, acc: 0.693359]  [A loss: 0.910493, acc: 0.250000]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "703: [D loss: 0.611055, acc: 0.667969]  [A loss: 0.928516, acc: 0.269531]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "704: [D loss: 0.624062, acc: 0.660156]  [A loss: 0.929045, acc: 0.281250]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "705: [D loss: 0.609910, acc: 0.667969]  [A loss: 0.937070, acc: 0.261719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "706: [D loss: 0.613024, acc: 0.687500]  [A loss: 0.960322, acc: 0.214844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "707: [D loss: 0.620471, acc: 0.679688]  [A loss: 0.976217, acc: 0.230469]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "708: [D loss: 0.577685, acc: 0.691406]  [A loss: 0.946493, acc: 0.265625]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "709: [D loss: 0.606216, acc: 0.677734]  [A loss: 0.952783, acc: 0.269531]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "710: [D loss: 0.588886, acc: 0.685547]  [A loss: 0.928625, acc: 0.296875]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "711: [D loss: 0.625780, acc: 0.646484]  [A loss: 1.022374, acc: 0.203125]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "712: [D loss: 0.622994, acc: 0.671875]  [A loss: 0.852868, acc: 0.347656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "713: [D loss: 0.595409, acc: 0.679688]  [A loss: 1.146133, acc: 0.148438]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "714: [D loss: 0.633522, acc: 0.640625]  [A loss: 0.843396, acc: 0.359375]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "715: [D loss: 0.621928, acc: 0.650391]  [A loss: 1.284933, acc: 0.097656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "716: [D loss: 0.634441, acc: 0.646484]  [A loss: 0.664007, acc: 0.566406]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "717: [D loss: 0.671679, acc: 0.601562]  [A loss: 1.287886, acc: 0.074219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "718: [D loss: 0.662268, acc: 0.605469]  [A loss: 0.777910, acc: 0.417969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "719: [D loss: 0.626669, acc: 0.656250]  [A loss: 1.044178, acc: 0.136719]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "720: [D loss: 0.636305, acc: 0.630859]  [A loss: 0.810674, acc: 0.367188]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "721: [D loss: 0.597527, acc: 0.705078]  [A loss: 1.027591, acc: 0.156250]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "722: [D loss: 0.612904, acc: 0.658203]  [A loss: 0.889702, acc: 0.296875]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "723: [D loss: 0.589156, acc: 0.697266]  [A loss: 0.974438, acc: 0.222656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "724: [D loss: 0.610684, acc: 0.664062]  [A loss: 0.973739, acc: 0.222656]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "725: [D loss: 0.611495, acc: 0.667969]  [A loss: 0.965742, acc: 0.269531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "726: [D loss: 0.611213, acc: 0.652344]  [A loss: 1.087692, acc: 0.140625]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "727: [D loss: 0.596598, acc: 0.679688]  [A loss: 0.879370, acc: 0.335938]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "728: [D loss: 0.595993, acc: 0.685547]  [A loss: 1.180517, acc: 0.140625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "729: [D loss: 0.634445, acc: 0.640625]  [A loss: 0.834125, acc: 0.347656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "730: [D loss: 0.613390, acc: 0.662109]  [A loss: 1.299475, acc: 0.109375]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "731: [D loss: 0.649338, acc: 0.623047]  [A loss: 0.762061, acc: 0.425781]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "732: [D loss: 0.623702, acc: 0.619141]  [A loss: 1.199777, acc: 0.101562]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "733: [D loss: 0.625755, acc: 0.644531]  [A loss: 0.789322, acc: 0.421875]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "734: [D loss: 0.633194, acc: 0.630859]  [A loss: 1.059699, acc: 0.160156]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "735: [D loss: 0.587416, acc: 0.707031]  [A loss: 0.909402, acc: 0.300781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "736: [D loss: 0.623079, acc: 0.632812]  [A loss: 1.053148, acc: 0.199219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "737: [D loss: 0.616751, acc: 0.646484]  [A loss: 0.887755, acc: 0.308594]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "738: [D loss: 0.640434, acc: 0.634766]  [A loss: 1.029218, acc: 0.191406]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "739: [D loss: 0.631501, acc: 0.630859]  [A loss: 0.854948, acc: 0.371094]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "740: [D loss: 0.605970, acc: 0.679688]  [A loss: 1.094618, acc: 0.164062]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "741: [D loss: 0.602355, acc: 0.685547]  [A loss: 0.819772, acc: 0.390625]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "742: [D loss: 0.627328, acc: 0.626953]  [A loss: 1.118185, acc: 0.167969]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "743: [D loss: 0.609020, acc: 0.654297]  [A loss: 0.842614, acc: 0.375000]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "744: [D loss: 0.623563, acc: 0.646484]  [A loss: 1.110723, acc: 0.121094]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "745: [D loss: 0.615793, acc: 0.638672]  [A loss: 0.851335, acc: 0.375000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "746: [D loss: 0.651676, acc: 0.623047]  [A loss: 1.074380, acc: 0.152344]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "747: [D loss: 0.631503, acc: 0.677734]  [A loss: 0.856470, acc: 0.316406]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "748: [D loss: 0.595590, acc: 0.689453]  [A loss: 1.045957, acc: 0.167969]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "749: [D loss: 0.615442, acc: 0.669922]  [A loss: 0.877207, acc: 0.304688]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "750: [D loss: 0.606192, acc: 0.671875]  [A loss: 1.008827, acc: 0.207031]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "751: [D loss: 0.609573, acc: 0.681641]  [A loss: 0.885613, acc: 0.332031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "752: [D loss: 0.616696, acc: 0.656250]  [A loss: 1.115574, acc: 0.160156]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "753: [D loss: 0.640404, acc: 0.634766]  [A loss: 0.855429, acc: 0.359375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "754: [D loss: 0.594116, acc: 0.681641]  [A loss: 1.204636, acc: 0.082031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "755: [D loss: 0.644564, acc: 0.656250]  [A loss: 0.790122, acc: 0.433594]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "756: [D loss: 0.639069, acc: 0.630859]  [A loss: 1.095888, acc: 0.125000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "757: [D loss: 0.596277, acc: 0.689453]  [A loss: 0.873171, acc: 0.296875]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "758: [D loss: 0.614978, acc: 0.654297]  [A loss: 1.177497, acc: 0.105469]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "759: [D loss: 0.607837, acc: 0.667969]  [A loss: 0.810550, acc: 0.390625]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "760: [D loss: 0.612874, acc: 0.642578]  [A loss: 1.138084, acc: 0.140625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "761: [D loss: 0.639588, acc: 0.630859]  [A loss: 0.865601, acc: 0.292969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "762: [D loss: 0.621614, acc: 0.662109]  [A loss: 1.054523, acc: 0.191406]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "763: [D loss: 0.593017, acc: 0.689453]  [A loss: 0.872077, acc: 0.343750]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "764: [D loss: 0.604526, acc: 0.693359]  [A loss: 1.117608, acc: 0.140625]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "765: [D loss: 0.622447, acc: 0.628906]  [A loss: 0.881832, acc: 0.308594]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "766: [D loss: 0.597627, acc: 0.662109]  [A loss: 1.078753, acc: 0.148438]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "767: [D loss: 0.603286, acc: 0.660156]  [A loss: 0.893278, acc: 0.328125]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "768: [D loss: 0.633992, acc: 0.623047]  [A loss: 1.139904, acc: 0.121094]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "769: [D loss: 0.616651, acc: 0.671875]  [A loss: 0.854305, acc: 0.339844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "770: [D loss: 0.614654, acc: 0.685547]  [A loss: 1.051372, acc: 0.164062]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "771: [D loss: 0.599870, acc: 0.681641]  [A loss: 0.938647, acc: 0.257812]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "772: [D loss: 0.595536, acc: 0.666016]  [A loss: 1.105041, acc: 0.125000]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "773: [D loss: 0.593140, acc: 0.666016]  [A loss: 0.824860, acc: 0.406250]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "774: [D loss: 0.628244, acc: 0.660156]  [A loss: 1.080861, acc: 0.136719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "775: [D loss: 0.631810, acc: 0.642578]  [A loss: 0.818894, acc: 0.414062]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "776: [D loss: 0.632693, acc: 0.660156]  [A loss: 1.150077, acc: 0.140625]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "777: [D loss: 0.615656, acc: 0.646484]  [A loss: 0.832608, acc: 0.371094]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "778: [D loss: 0.599500, acc: 0.683594]  [A loss: 1.199692, acc: 0.121094]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "779: [D loss: 0.636137, acc: 0.640625]  [A loss: 0.748385, acc: 0.457031]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "780: [D loss: 0.598558, acc: 0.683594]  [A loss: 1.092355, acc: 0.125000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "781: [D loss: 0.588056, acc: 0.708984]  [A loss: 0.892109, acc: 0.296875]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "782: [D loss: 0.583396, acc: 0.699219]  [A loss: 1.107922, acc: 0.167969]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "783: [D loss: 0.599454, acc: 0.666016]  [A loss: 0.827451, acc: 0.359375]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "784: [D loss: 0.616217, acc: 0.681641]  [A loss: 1.182861, acc: 0.121094]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "785: [D loss: 0.649881, acc: 0.615234]  [A loss: 0.827395, acc: 0.367188]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "786: [D loss: 0.605930, acc: 0.671875]  [A loss: 1.135563, acc: 0.132812]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "787: [D loss: 0.615991, acc: 0.654297]  [A loss: 0.809293, acc: 0.410156]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "788: [D loss: 0.607612, acc: 0.664062]  [A loss: 1.114254, acc: 0.128906]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "789: [D loss: 0.601561, acc: 0.669922]  [A loss: 0.889572, acc: 0.304688]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "790: [D loss: 0.591362, acc: 0.708984]  [A loss: 1.152313, acc: 0.128906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "791: [D loss: 0.584571, acc: 0.687500]  [A loss: 0.864861, acc: 0.328125]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "792: [D loss: 0.610611, acc: 0.646484]  [A loss: 1.118356, acc: 0.164062]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "793: [D loss: 0.578879, acc: 0.697266]  [A loss: 1.016871, acc: 0.195312]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "794: [D loss: 0.617359, acc: 0.667969]  [A loss: 1.006699, acc: 0.238281]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "795: [D loss: 0.604749, acc: 0.677734]  [A loss: 1.010184, acc: 0.222656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "796: [D loss: 0.613303, acc: 0.654297]  [A loss: 0.930101, acc: 0.273438]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "797: [D loss: 0.609676, acc: 0.654297]  [A loss: 1.017420, acc: 0.171875]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "798: [D loss: 0.600636, acc: 0.673828]  [A loss: 1.096181, acc: 0.179688]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "799: [D loss: 0.595424, acc: 0.693359]  [A loss: 0.872165, acc: 0.335938]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "800: [D loss: 0.601597, acc: 0.671875]  [A loss: 1.251875, acc: 0.089844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "801: [D loss: 0.609807, acc: 0.679688]  [A loss: 0.709850, acc: 0.554688]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "802: [D loss: 0.613098, acc: 0.652344]  [A loss: 1.260586, acc: 0.074219]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "803: [D loss: 0.595980, acc: 0.683594]  [A loss: 0.844523, acc: 0.347656]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "804: [D loss: 0.619585, acc: 0.640625]  [A loss: 1.193062, acc: 0.089844]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "805: [D loss: 0.628429, acc: 0.626953]  [A loss: 0.919463, acc: 0.292969]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "806: [D loss: 0.600623, acc: 0.660156]  [A loss: 1.116617, acc: 0.152344]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "807: [D loss: 0.617221, acc: 0.642578]  [A loss: 0.824751, acc: 0.390625]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "808: [D loss: 0.606766, acc: 0.679688]  [A loss: 1.099540, acc: 0.191406]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "809: [D loss: 0.590014, acc: 0.703125]  [A loss: 0.905312, acc: 0.335938]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "810: [D loss: 0.589973, acc: 0.695312]  [A loss: 1.141184, acc: 0.160156]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "811: [D loss: 0.592414, acc: 0.681641]  [A loss: 0.826250, acc: 0.386719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "812: [D loss: 0.633782, acc: 0.650391]  [A loss: 1.259963, acc: 0.101562]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "813: [D loss: 0.618656, acc: 0.644531]  [A loss: 0.779160, acc: 0.449219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "814: [D loss: 0.618550, acc: 0.664062]  [A loss: 1.136126, acc: 0.101562]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "815: [D loss: 0.618823, acc: 0.652344]  [A loss: 0.886779, acc: 0.300781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "816: [D loss: 0.600267, acc: 0.673828]  [A loss: 1.191729, acc: 0.109375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "817: [D loss: 0.633295, acc: 0.650391]  [A loss: 0.841768, acc: 0.351562]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "818: [D loss: 0.577086, acc: 0.710938]  [A loss: 1.058973, acc: 0.152344]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "819: [D loss: 0.598553, acc: 0.685547]  [A loss: 0.974158, acc: 0.253906]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "820: [D loss: 0.613065, acc: 0.693359]  [A loss: 1.034632, acc: 0.210938]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "821: [D loss: 0.590106, acc: 0.681641]  [A loss: 1.058541, acc: 0.207031]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "822: [D loss: 0.584528, acc: 0.695312]  [A loss: 0.981127, acc: 0.253906]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "823: [D loss: 0.599219, acc: 0.695312]  [A loss: 1.086862, acc: 0.187500]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "824: [D loss: 0.612791, acc: 0.658203]  [A loss: 0.871705, acc: 0.320312]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "825: [D loss: 0.591107, acc: 0.689453]  [A loss: 1.130941, acc: 0.117188]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "826: [D loss: 0.641387, acc: 0.636719]  [A loss: 0.876719, acc: 0.308594]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "827: [D loss: 0.632568, acc: 0.634766]  [A loss: 1.151647, acc: 0.148438]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "828: [D loss: 0.638290, acc: 0.615234]  [A loss: 0.824417, acc: 0.375000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "829: [D loss: 0.624961, acc: 0.679688]  [A loss: 1.246776, acc: 0.082031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "830: [D loss: 0.600697, acc: 0.693359]  [A loss: 0.827764, acc: 0.359375]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "831: [D loss: 0.591902, acc: 0.693359]  [A loss: 1.157318, acc: 0.128906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "832: [D loss: 0.630707, acc: 0.638672]  [A loss: 0.892947, acc: 0.292969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "833: [D loss: 0.609010, acc: 0.683594]  [A loss: 1.039307, acc: 0.191406]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "834: [D loss: 0.589974, acc: 0.699219]  [A loss: 0.941342, acc: 0.261719]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "835: [D loss: 0.593818, acc: 0.701172]  [A loss: 1.024359, acc: 0.203125]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "836: [D loss: 0.597079, acc: 0.675781]  [A loss: 0.915771, acc: 0.312500]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "837: [D loss: 0.604871, acc: 0.671875]  [A loss: 1.154411, acc: 0.121094]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "838: [D loss: 0.621235, acc: 0.664062]  [A loss: 0.862763, acc: 0.292969]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "839: [D loss: 0.620929, acc: 0.675781]  [A loss: 1.092417, acc: 0.140625]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "840: [D loss: 0.616788, acc: 0.650391]  [A loss: 0.986232, acc: 0.222656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "841: [D loss: 0.602938, acc: 0.701172]  [A loss: 1.019936, acc: 0.210938]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "842: [D loss: 0.585954, acc: 0.701172]  [A loss: 1.086910, acc: 0.160156]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "843: [D loss: 0.593257, acc: 0.673828]  [A loss: 0.940075, acc: 0.296875]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "844: [D loss: 0.596988, acc: 0.683594]  [A loss: 1.097403, acc: 0.183594]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "845: [D loss: 0.585533, acc: 0.681641]  [A loss: 0.894110, acc: 0.300781]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "846: [D loss: 0.593977, acc: 0.681641]  [A loss: 1.173786, acc: 0.136719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "847: [D loss: 0.594569, acc: 0.675781]  [A loss: 0.839107, acc: 0.367188]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "848: [D loss: 0.599614, acc: 0.660156]  [A loss: 1.249270, acc: 0.109375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "849: [D loss: 0.596352, acc: 0.681641]  [A loss: 0.782281, acc: 0.445312]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "850: [D loss: 0.639634, acc: 0.652344]  [A loss: 1.271813, acc: 0.121094]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "851: [D loss: 0.625927, acc: 0.630859]  [A loss: 0.792512, acc: 0.402344]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "852: [D loss: 0.603748, acc: 0.638672]  [A loss: 1.165372, acc: 0.128906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "853: [D loss: 0.606224, acc: 0.671875]  [A loss: 0.906122, acc: 0.285156]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "854: [D loss: 0.615211, acc: 0.648438]  [A loss: 1.043617, acc: 0.187500]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "855: [D loss: 0.576050, acc: 0.693359]  [A loss: 0.984343, acc: 0.238281]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "856: [D loss: 0.598443, acc: 0.664062]  [A loss: 1.141840, acc: 0.109375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "857: [D loss: 0.591792, acc: 0.681641]  [A loss: 0.845724, acc: 0.332031]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "858: [D loss: 0.591887, acc: 0.695312]  [A loss: 1.109946, acc: 0.167969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "859: [D loss: 0.588506, acc: 0.718750]  [A loss: 0.954389, acc: 0.292969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "860: [D loss: 0.583497, acc: 0.701172]  [A loss: 1.147631, acc: 0.175781]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "861: [D loss: 0.581923, acc: 0.697266]  [A loss: 0.921278, acc: 0.292969]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "862: [D loss: 0.612880, acc: 0.650391]  [A loss: 1.089848, acc: 0.132812]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "863: [D loss: 0.593093, acc: 0.693359]  [A loss: 0.921494, acc: 0.273438]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "864: [D loss: 0.630432, acc: 0.638672]  [A loss: 1.350623, acc: 0.085938]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "865: [D loss: 0.646203, acc: 0.619141]  [A loss: 0.702376, acc: 0.527344]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "866: [D loss: 0.627494, acc: 0.626953]  [A loss: 1.228740, acc: 0.109375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "867: [D loss: 0.634907, acc: 0.632812]  [A loss: 0.917922, acc: 0.261719]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "868: [D loss: 0.635777, acc: 0.654297]  [A loss: 1.095568, acc: 0.156250]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "869: [D loss: 0.602643, acc: 0.685547]  [A loss: 0.875727, acc: 0.355469]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "870: [D loss: 0.586644, acc: 0.703125]  [A loss: 1.062994, acc: 0.164062]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "871: [D loss: 0.597813, acc: 0.683594]  [A loss: 0.967951, acc: 0.230469]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "872: [D loss: 0.583113, acc: 0.707031]  [A loss: 1.059835, acc: 0.175781]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "873: [D loss: 0.622671, acc: 0.626953]  [A loss: 1.084158, acc: 0.152344]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "874: [D loss: 0.607730, acc: 0.654297]  [A loss: 0.885194, acc: 0.296875]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "875: [D loss: 0.602046, acc: 0.667969]  [A loss: 1.143177, acc: 0.140625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "876: [D loss: 0.576194, acc: 0.697266]  [A loss: 0.901571, acc: 0.332031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "877: [D loss: 0.601123, acc: 0.646484]  [A loss: 1.155175, acc: 0.148438]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "878: [D loss: 0.591041, acc: 0.687500]  [A loss: 0.916744, acc: 0.292969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "879: [D loss: 0.623627, acc: 0.648438]  [A loss: 1.227885, acc: 0.089844]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "880: [D loss: 0.622819, acc: 0.644531]  [A loss: 0.809011, acc: 0.382812]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "881: [D loss: 0.617449, acc: 0.642578]  [A loss: 1.139825, acc: 0.140625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "882: [D loss: 0.582797, acc: 0.695312]  [A loss: 0.922339, acc: 0.312500]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "883: [D loss: 0.599649, acc: 0.664062]  [A loss: 1.125336, acc: 0.132812]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "884: [D loss: 0.639677, acc: 0.636719]  [A loss: 1.039760, acc: 0.179688]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "885: [D loss: 0.612204, acc: 0.669922]  [A loss: 0.984302, acc: 0.222656]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "886: [D loss: 0.594765, acc: 0.681641]  [A loss: 1.059306, acc: 0.183594]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "887: [D loss: 0.600380, acc: 0.681641]  [A loss: 1.041975, acc: 0.203125]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "888: [D loss: 0.593485, acc: 0.693359]  [A loss: 0.935844, acc: 0.277344]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "889: [D loss: 0.607424, acc: 0.658203]  [A loss: 1.164972, acc: 0.140625]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "890: [D loss: 0.602074, acc: 0.689453]  [A loss: 0.836904, acc: 0.398438]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "891: [D loss: 0.609742, acc: 0.677734]  [A loss: 1.264645, acc: 0.085938]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "892: [D loss: 0.622212, acc: 0.640625]  [A loss: 0.787715, acc: 0.472656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "893: [D loss: 0.630889, acc: 0.656250]  [A loss: 1.306467, acc: 0.089844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "894: [D loss: 0.618576, acc: 0.640625]  [A loss: 0.744652, acc: 0.468750]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "895: [D loss: 0.595150, acc: 0.683594]  [A loss: 1.094861, acc: 0.144531]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "896: [D loss: 0.583438, acc: 0.701172]  [A loss: 0.975818, acc: 0.214844]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "897: [D loss: 0.617075, acc: 0.632812]  [A loss: 1.181424, acc: 0.109375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "898: [D loss: 0.595666, acc: 0.679688]  [A loss: 0.907880, acc: 0.292969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "899: [D loss: 0.606332, acc: 0.685547]  [A loss: 1.071310, acc: 0.203125]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "900: [D loss: 0.629127, acc: 0.650391]  [A loss: 0.866336, acc: 0.320312]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "901: [D loss: 0.600776, acc: 0.669922]  [A loss: 1.104728, acc: 0.164062]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "902: [D loss: 0.573628, acc: 0.708984]  [A loss: 0.947634, acc: 0.269531]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "903: [D loss: 0.618652, acc: 0.667969]  [A loss: 1.261039, acc: 0.085938]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "904: [D loss: 0.602902, acc: 0.662109]  [A loss: 0.822466, acc: 0.406250]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "905: [D loss: 0.615706, acc: 0.681641]  [A loss: 1.147680, acc: 0.101562]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "906: [D loss: 0.588428, acc: 0.687500]  [A loss: 0.906714, acc: 0.277344]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "907: [D loss: 0.601763, acc: 0.693359]  [A loss: 1.150164, acc: 0.117188]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "908: [D loss: 0.593437, acc: 0.673828]  [A loss: 0.997240, acc: 0.253906]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "909: [D loss: 0.617361, acc: 0.666016]  [A loss: 1.035646, acc: 0.238281]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "910: [D loss: 0.595804, acc: 0.697266]  [A loss: 0.910131, acc: 0.285156]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "911: [D loss: 0.607638, acc: 0.671875]  [A loss: 1.040879, acc: 0.195312]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "912: [D loss: 0.582091, acc: 0.695312]  [A loss: 0.961159, acc: 0.261719]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "913: [D loss: 0.567794, acc: 0.710938]  [A loss: 1.067012, acc: 0.214844]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "914: [D loss: 0.595980, acc: 0.671875]  [A loss: 0.929536, acc: 0.265625]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "915: [D loss: 0.575352, acc: 0.716797]  [A loss: 1.161410, acc: 0.093750]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "916: [D loss: 0.575553, acc: 0.699219]  [A loss: 0.962903, acc: 0.292969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "917: [D loss: 0.599444, acc: 0.689453]  [A loss: 1.442413, acc: 0.050781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "918: [D loss: 0.590289, acc: 0.667969]  [A loss: 0.769190, acc: 0.476562]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "919: [D loss: 0.647155, acc: 0.628906]  [A loss: 1.339272, acc: 0.082031]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "920: [D loss: 0.608448, acc: 0.660156]  [A loss: 0.874058, acc: 0.332031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "921: [D loss: 0.603044, acc: 0.693359]  [A loss: 1.125276, acc: 0.132812]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "922: [D loss: 0.625671, acc: 0.638672]  [A loss: 1.018518, acc: 0.191406]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "923: [D loss: 0.594963, acc: 0.673828]  [A loss: 1.153386, acc: 0.164062]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "924: [D loss: 0.613104, acc: 0.652344]  [A loss: 0.995935, acc: 0.261719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "925: [D loss: 0.604333, acc: 0.666016]  [A loss: 1.003978, acc: 0.226562]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "926: [D loss: 0.571194, acc: 0.689453]  [A loss: 1.046299, acc: 0.195312]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "927: [D loss: 0.587194, acc: 0.693359]  [A loss: 1.043456, acc: 0.222656]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "928: [D loss: 0.568305, acc: 0.718750]  [A loss: 0.960945, acc: 0.261719]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "929: [D loss: 0.616217, acc: 0.662109]  [A loss: 1.122555, acc: 0.164062]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "930: [D loss: 0.575087, acc: 0.701172]  [A loss: 0.904035, acc: 0.320312]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "931: [D loss: 0.608236, acc: 0.671875]  [A loss: 1.328967, acc: 0.074219]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "932: [D loss: 0.587032, acc: 0.693359]  [A loss: 0.828886, acc: 0.421875]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "933: [D loss: 0.645547, acc: 0.640625]  [A loss: 1.295430, acc: 0.097656]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "934: [D loss: 0.633082, acc: 0.648438]  [A loss: 0.904255, acc: 0.300781]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "935: [D loss: 0.608087, acc: 0.681641]  [A loss: 1.174962, acc: 0.121094]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "936: [D loss: 0.594685, acc: 0.693359]  [A loss: 0.962048, acc: 0.265625]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "937: [D loss: 0.589077, acc: 0.699219]  [A loss: 1.063232, acc: 0.195312]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "938: [D loss: 0.578356, acc: 0.695312]  [A loss: 1.000134, acc: 0.253906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "939: [D loss: 0.621464, acc: 0.654297]  [A loss: 1.256183, acc: 0.105469]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "940: [D loss: 0.606923, acc: 0.648438]  [A loss: 0.824058, acc: 0.398438]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "941: [D loss: 0.620460, acc: 0.648438]  [A loss: 1.206734, acc: 0.101562]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "942: [D loss: 0.618179, acc: 0.658203]  [A loss: 0.856961, acc: 0.324219]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "943: [D loss: 0.583595, acc: 0.679688]  [A loss: 1.255307, acc: 0.089844]\n",
      "8/8 [==============================] - 0s 6ms/step\n",
      "944: [D loss: 0.590683, acc: 0.669922]  [A loss: 0.954778, acc: 0.265625]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "945: [D loss: 0.612126, acc: 0.677734]  [A loss: 1.108430, acc: 0.191406]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "946: [D loss: 0.596443, acc: 0.691406]  [A loss: 0.996389, acc: 0.238281]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "947: [D loss: 0.608131, acc: 0.679688]  [A loss: 1.042915, acc: 0.203125]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "948: [D loss: 0.592603, acc: 0.691406]  [A loss: 1.113387, acc: 0.171875]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "949: [D loss: 0.596535, acc: 0.710938]  [A loss: 1.016996, acc: 0.199219]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "950: [D loss: 0.592761, acc: 0.701172]  [A loss: 1.088908, acc: 0.175781]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "951: [D loss: 0.598993, acc: 0.648438]  [A loss: 0.952096, acc: 0.253906]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "952: [D loss: 0.603239, acc: 0.679688]  [A loss: 1.029726, acc: 0.199219]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "953: [D loss: 0.606781, acc: 0.675781]  [A loss: 1.032497, acc: 0.226562]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "954: [D loss: 0.591123, acc: 0.673828]  [A loss: 1.023456, acc: 0.222656]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "955: [D loss: 0.621854, acc: 0.662109]  [A loss: 1.018882, acc: 0.230469]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "956: [D loss: 0.583388, acc: 0.703125]  [A loss: 1.087226, acc: 0.183594]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "957: [D loss: 0.600100, acc: 0.673828]  [A loss: 1.118308, acc: 0.167969]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "958: [D loss: 0.580859, acc: 0.703125]  [A loss: 1.037971, acc: 0.195312]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "959: [D loss: 0.614500, acc: 0.638672]  [A loss: 1.068671, acc: 0.195312]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "960: [D loss: 0.605586, acc: 0.675781]  [A loss: 1.037747, acc: 0.210938]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "961: [D loss: 0.579695, acc: 0.708984]  [A loss: 1.023410, acc: 0.230469]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "962: [D loss: 0.603259, acc: 0.664062]  [A loss: 1.148380, acc: 0.125000]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "963: [D loss: 0.577530, acc: 0.681641]  [A loss: 1.047620, acc: 0.195312]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "964: [D loss: 0.598261, acc: 0.669922]  [A loss: 0.988503, acc: 0.222656]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "965: [D loss: 0.605794, acc: 0.687500]  [A loss: 1.075902, acc: 0.203125]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "966: [D loss: 0.580398, acc: 0.714844]  [A loss: 0.969257, acc: 0.281250]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "967: [D loss: 0.588795, acc: 0.689453]  [A loss: 1.158022, acc: 0.156250]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "968: [D loss: 0.581857, acc: 0.718750]  [A loss: 0.911359, acc: 0.332031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "969: [D loss: 0.626782, acc: 0.642578]  [A loss: 1.388719, acc: 0.058594]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "970: [D loss: 0.654880, acc: 0.613281]  [A loss: 0.666578, acc: 0.578125]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "971: [D loss: 0.615184, acc: 0.630859]  [A loss: 1.328293, acc: 0.046875]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "972: [D loss: 0.622028, acc: 0.648438]  [A loss: 0.854664, acc: 0.347656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "973: [D loss: 0.627476, acc: 0.628906]  [A loss: 1.380727, acc: 0.066406]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "974: [D loss: 0.627750, acc: 0.644531]  [A loss: 0.851565, acc: 0.347656]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "975: [D loss: 0.578531, acc: 0.708984]  [A loss: 1.101873, acc: 0.187500]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "976: [D loss: 0.585442, acc: 0.693359]  [A loss: 1.034921, acc: 0.167969]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "977: [D loss: 0.559419, acc: 0.714844]  [A loss: 1.051861, acc: 0.203125]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "978: [D loss: 0.592296, acc: 0.695312]  [A loss: 1.135964, acc: 0.156250]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "979: [D loss: 0.613330, acc: 0.662109]  [A loss: 0.997301, acc: 0.269531]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "980: [D loss: 0.592338, acc: 0.675781]  [A loss: 1.095735, acc: 0.199219]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "981: [D loss: 0.594664, acc: 0.691406]  [A loss: 0.909453, acc: 0.324219]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "982: [D loss: 0.588006, acc: 0.683594]  [A loss: 1.212124, acc: 0.152344]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "983: [D loss: 0.597442, acc: 0.666016]  [A loss: 0.992127, acc: 0.253906]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "984: [D loss: 0.585449, acc: 0.691406]  [A loss: 1.154035, acc: 0.148438]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "985: [D loss: 0.601692, acc: 0.671875]  [A loss: 0.941154, acc: 0.289062]\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "986: [D loss: 0.597205, acc: 0.673828]  [A loss: 1.002982, acc: 0.226562]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "987: [D loss: 0.574697, acc: 0.716797]  [A loss: 1.007035, acc: 0.203125]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "988: [D loss: 0.573412, acc: 0.710938]  [A loss: 1.081187, acc: 0.226562]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "989: [D loss: 0.598624, acc: 0.664062]  [A loss: 0.860092, acc: 0.359375]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "990: [D loss: 0.638877, acc: 0.625000]  [A loss: 1.305310, acc: 0.074219]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "991: [D loss: 0.608788, acc: 0.673828]  [A loss: 0.836783, acc: 0.359375]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "992: [D loss: 0.642062, acc: 0.640625]  [A loss: 1.251966, acc: 0.113281]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "993: [D loss: 0.586046, acc: 0.687500]  [A loss: 0.894082, acc: 0.332031]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "994: [D loss: 0.607051, acc: 0.685547]  [A loss: 1.118734, acc: 0.156250]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "995: [D loss: 0.609938, acc: 0.650391]  [A loss: 1.024730, acc: 0.218750]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "996: [D loss: 0.578924, acc: 0.712891]  [A loss: 1.065889, acc: 0.171875]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "997: [D loss: 0.588885, acc: 0.679688]  [A loss: 0.972006, acc: 0.253906]\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "998: [D loss: 0.631481, acc: 0.654297]  [A loss: 1.043966, acc: 0.187500]\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "999: [D loss: 0.613857, acc: 0.646484]  [A loss: 0.978192, acc: 0.265625]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Elapsed: 5.200454084078471 min \n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timer = ElapsedTimer()\n",
    "train(train_epochs=1000, batch_size=256, save_interval=100)\n",
    "timer.elapsed_time()\n",
    "plot_images(fake=True)\n",
    "plot_images(fake=False, saveToFile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSWP_H8ZT1tK"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<p><strong>Ejercicio [1 pts.]:</strong>\n",
    "Contesta a las siguientes preguntas:\n",
    "</div>\n",
    "\n",
    "**1. Explica qué hacen las siguientes líneas de código:**\n",
    "\n",
    "```python\n",
    "timer = ElapsedTimer()\n",
    "train(train_epochs=1000, batch_size=256, save_interval=100)\n",
    "timer.elapsed_time()\n",
    "plot_images(fake=True)\n",
    "plot_images(fake=False, saveToFile=True)\n",
    "```\n",
    "timer = ElapsedTimer(): Esta línea crea un temporizador que se utiliza para medir el tiempo de entrenamiento del modelo GAN. Podemos observarlo al final de la ejecución que indica: Elapsed: 5.200454084078471 min<br><br>\n",
    "train(train_epochs=1000, batch_size=256, save_interval=100): Esta línea realiza el entrenamiento del modelo GAN. Especificamos la cantidad de épocas que se ejecutará (1000) y el tamaño de lote (256). El parámetro save_interval indica cada qué invervalo de iteraciones guardamos las imágenes.<br><br>\n",
    "timer.elapsed_time(): Esta línea devuelve el tiempo transcurrido del timer que hemos creado antes del entrenamiento. Mide la duración total del entrenamiento del modelo GAN.<br><br>\n",
    "plot_images(fake=True): Esta línea llama a la función que creada anteriormente. Al no especificar el parámetro saveToFile, mostramos por pantalla el resultado. En este caso, mostramos 16 imágenes falsas generadas por el generador a partir de un ruido aleatorio.<br><br>\n",
    "plot_images(fake=False, saveToFile=True): Esta línea similar a la anterior llama a la función plot_images. En este caso, pasamos el parametro fake=False, por lo que en lugar de generar imágenes, se escogen imágenes reales del conjunto de entrenamiento. Además, se añade el parametro saveToFile, por lo que en lugar de mostrar el resultado en el notebook se guarda en un fichero con el nombre mnist.png\n",
    "\n",
    "**2. Escribe el código necesario para mostrar las imágenes generadas en la última iteración y muestra los resultados:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NwIzk8kgT1tK"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "# La última iteración es la 1000\n",
    "image_path = 'images/mnist_1000.png'\n",
    "\n",
    "# Mostramos la imagen\n",
    "plt.imshow(mpimg.imread(image_path))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLv2bo3UT1tK"
   },
   "source": [
    "# Referencias consultadas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cFxBvSuT1tK"
   },
   "source": [
    "* Añadir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6jmUdeeT1tK"
   },
   "source": [
    "https://developers.google.com/machine-learning/gan/gan_structure\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental/RMSprop\n",
    "\n",
    "https://deepchecks.com/glossary/rmsprop/#:~:text=RMSprop%20is%20an%20innovative%20stochastic,and%20other%20Machine%20Learning%20techniques\n",
    "\n",
    "https://datascience.stackexchange.com/questions/26792/difference-between-rmsprop-with-momentum-and-adam-optimizers#:~:text=Adam%20is%20slower%20to%20change,both%20use%20the%20same%20learning_rate)\n",
    "\n",
    "https://keras.io/api/layers/activation_layers/leaky_relu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
